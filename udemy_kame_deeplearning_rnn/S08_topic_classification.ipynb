{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Classification"
      ],
      "metadata": {
        "id": "8yN_s0kVwWrA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jEOz2qrlwVFA",
        "outputId": "e77f9394-a973-470d-f375-038159918bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.1.0\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 torch-2.1.0 triton-2.1.0\n",
            "Collecting torchtext==0.16.0\n",
            "  Downloading torchtext-0.16.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.16.0) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.16.0) (2.32.3)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.16.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.16.0) (1.26.4)\n",
            "Collecting torchdata==0.7.0 (from torchtext==0.16.0)\n",
            "  Downloading torchdata-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16.0) (2.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0->torchtext==0.16.0) (2.2.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchtext==0.16.0) (12.6.77)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.16.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.16.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.16.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchtext==0.16.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchtext==0.16.0) (1.3.0)\n",
            "Downloading torchtext-0.16.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchdata, torchtext\n",
            "Successfully installed torchdata-0.7.0 torchtext-0.16.0\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch=='2.1.0'\n",
        "!pip install torchtext==0.16.0\n",
        "!pip install portalocker"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データ準備"
      ],
      "metadata": {
        "id": "xmhkzYXV2pvl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- トピック分類のサンプルデータを、RNNで学習できる形に処理する\n",
        "  - データをロード：torchtext.dataset.AG_NEWSクラス\n",
        "    - portalockerを事前にインストール\n",
        "    - ニュース記事のトピック分類のデータ(Worlds,Sports, Business, Sci/Tech)\n",
        "    - split: 'train' or 'test'\n",
        "    - イテレータを返す\n",
        "  - 今回はデータ数を減らすため、split='train'データのみを使用する\n",
        "- 学習データと検証データに分割する(学習データ10%、検証データ9%)\n",
        "- それぞれの分の長さの分布等を確認する"
      ],
      "metadata": {
        "id": "BLi-0XijxX1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = datasets.AG_NEWS(split='train')\n",
        "data = list(data)\n",
        "train_data, remaining = train_test_split(data, train_size=0.1, random_state=0)\n",
        "_, val_data = train_test_split(remaining, test_size=0.1, random_state=0)"
      ],
      "metadata": {
        "id": "caltKSYdwjqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ラベルについて\n",
        "# 1: \"World\", 2:\"Sports\", 3:\"Business\", 4:\"Sci/Tech\"\n",
        "list(data)[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNu3zpuRyYD9",
        "outputId": "fb632823-512d-43f5-8f79-4195cc8d52f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3,\n",
              "  \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\"),\n",
              " (3,\n",
              "  'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.'),\n",
              " (3,\n",
              "  \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "labels = [label for label, text in data]\n",
        "labels = pd.Series(labels)\n",
        "labels.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "Lu0RnZzwz6bO",
        "outputId": "64b4091f-b821-49be-b603-ee56fc71cc05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    30000\n",
              "4    30000\n",
              "2    30000\n",
              "1    30000\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# index:0のtext\n",
        "print(data[0][1])\n",
        "\n",
        "# 単語のみ抜き出す\n",
        "print(data[0][1].split())\n",
        "\n",
        "# 文の長さを確認する\n",
        "print(len(data[0][1].split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqoKbbtS1HCO",
        "outputId": "55b2a87f-a827-4cd5-99c3-147b5fa12d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
            "['Wall', 'St.', 'Bears', 'Claw', 'Back', 'Into', 'the', 'Black', '(Reuters)', 'Reuters', '-', 'Short-sellers,', 'Wall', \"Street's\", 'dwindling\\\\band', 'of', 'ultra-cynics,', 'are', 'seeing', 'green', 'again.']\n",
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文の長さの分布確認\n",
        "import seaborn as sns\n",
        "text_lens = pd.Series([len(text.split()) for _, text in data])\n",
        "sns.histplot(text_lens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "w4yE-awn0rFf",
        "outputId": "d0c39a9a-3980-469c-a1e8-5b5a048d4283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Count'>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGdCAYAAADzOWwgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvy0lEQVR4nO3de3wV9Z3/8fcBcuNyEgGTkHILokCUi6CGs21dLimBplZLdhctKlXQwgYqsEWWXQTE7eIDV/AWoV2RuD+lCI+HlwIWDImAlHAxkMpF8xA3GjQkaaU5A0gSIN/fH27GHJIAicmZJPN6Ph7zIGfmO5PPDJPw5jvfmfEYY4wAAABcrJ3TBQAAADiNQAQAAFyPQAQAAFyPQAQAAFyPQAQAAFyPQAQAAFyPQAQAAFyPQAQAAFyvg9MFtAZVVVUqKipSly5d5PF4nC4HAABcBWOMTp8+rbi4OLVrd/k+IALRVSgqKlKvXr2cLgMAADTCiRMn1LNnz8u2IRBdhS5dukj65oB6vV6HqwEAAFfDsiz16tXL/nf8cghEV6H6MpnX6yUQAQDQylzNcBcGVQMAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEKFNMMbI7/fLGON0KQCAVohAhFatOgj5/X5NWrFJlmU5XRIAoBUiEKHFqhl2avb81OwNsizLDkIhEZ0crBYA0JoRiNBiWZale1dl695V2QE9PzVDkCSCEADgO+vgdAHA5YREdK5nPiEIANB06CECAACuRyBCq8BdZACA5kQgQqtw6bghAACaEoEIrQbjhgAAzYVABAAAXI9ABAAAXI9ABAAAXI9ABAAAXI8HM6JNqb49X5K8Xq88Ho/DFQEAWgMCEdoUy7KUti5XkvTqjDGKjIx0uCIAQGtAIEKbU9/rPgAAqA9jiAAAgOsRiAAAgOtxyQwtjjFGlmXx3jIAQNDQQ4QWh/eWAQCCjUCEFon3lgEAgolABAAAXI9ABAAAXI9ABAAAXI9AhDat+lUe3LEGALgcAhHaNO5YAwBcDQIR2jzuWAMAXAmBCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuJ6jgWjJkiXyeDwB08CBA+3l5eXlSktLU7du3dS5c2elpqaqpKQkYBuFhYVKSUlRx44dFR0drXnz5unChQsBbXbs2KHhw4crLCxM/fv3V0ZGRjB2DwAAtBKO9xDdeOONOnnypD3t3r3bXjZnzhxt2rRJGzdu1M6dO1VUVKSJEyfayy9evKiUlBRVVlZqz549euWVV5SRkaFFixbZbQoKCpSSkqLRo0crLy9Ps2fP1rRp07Rt27ag7iecZYyR3++X3++XMcbpcgAALUwHxwvo0EGxsbG15vv9fq1Zs0br1q3TmDFjJElr167VoEGDtHfvXo0cOVLvvvuujh07pu3btysmJkbDhg3TE088ofnz52vJkiUKDQ3V6tWrFR8fr6efflqSNGjQIO3evVsrV65UcnJyUPcVzrEsS2nrciVJr84Yo8jISIcrAgC0JI73EH3yySeKi4tTv379NHnyZBUWFkqScnNzdf78eSUlJdltBw4cqN69eysnJ0eSlJOTo8GDBysmJsZuk5ycLMuydPToUbtNzW1Ut6neRl0qKipkWVbAhOZX3YvTXD04IRGdFRLRuVm2DQBo3RwNRImJicrIyNDWrVu1atUqFRQU6Ic//KFOnz6t4uJihYaGKioqKmCdmJgYFRcXS5KKi4sDwlD18upll2tjWZbOnTtXZ13Lli1TZGSkPfXq1aspdhdXYFmWJq3YRAAFAASdo5fMJkyYYH89ZMgQJSYmqk+fPtqwYYMiIiIcq2vBggWaO3eu/dmyLEJRkIREdHK6BACACzl+yaymqKgo3XDDDTp+/LhiY2NVWVmpsrKygDYlJSX2mKPY2Nhad51Vf75SG6/XW2/oCgsLk9frDZgAAEDb1aIC0ZkzZ/Tpp5+qR48eGjFihEJCQpSVlWUvz8/PV2FhoXw+nyTJ5/Pp8OHDKi0ttdtkZmbK6/UqISHBblNzG9VtqrcBAADgaCD69a9/rZ07d+qzzz7Tnj179LOf/Uzt27fXPffco8jISE2dOlVz587Ve++9p9zcXD3wwAPy+XwaOXKkJGncuHFKSEjQfffdpz//+c/atm2bFi5cqLS0NIWFhUmSpk+frv/93//Vo48+qo8//lgvvviiNmzYoDlz5ji56wAAoAVxdAzRF198oXvuuUdfffWVrr32Wv3gBz/Q3r17de2110qSVq5cqXbt2ik1NVUVFRVKTk7Wiy++aK/fvn17bd68WTNmzJDP51OnTp00ZcoULV261G4THx+vLVu2aM6cOXr22WfVs2dPvfTSS9xyDwAAbI4GovXr1192eXh4uNLT05Wenl5vmz59+uidd9657HZGjRqlQ4cONapGAADQ9rWoMUQAAABOIBABAADXIxABAADXIxABAADXIxDBMc397jIAAK4WgQiO4d1lAICWgkAER/HuMgBAS0AgAgAArkcgAgAArkcgAgAArkcgAgAArkcggutwuz8A4FIEIrgOt/sDAC5FIIIrcbs/AKAmAhEAAHA9AhEAAHA9AhEAAHA9AhEAAHA9AhEAAHA9AhEAAHA9AhEAAHA9AhEAAHA9AhEAAHA9AhEAAHA9AhEAAHA9AhEAAHA9AhEAAHA9AhEAAHC9Dk4XAPcxxsiyLBljnC4FAABJ9BDBAZZladKKTbIsy+lSAACQRCCCQ0IiOjldAgAANgIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRXMsYI7/fL2OM06UAABxGIIJrWZalSSs2ybIsp0sBADiMQARXC4no5HQJAIAWgEAEAABcj0AEAABcr8UEoieffFIej0ezZ8+255WXlystLU3dunVT586dlZqaqpKSkoD1CgsLlZKSoo4dOyo6Olrz5s3ThQsXAtrs2LFDw4cPV1hYmPr376+MjIwg7BEAAGgtWkQgOnDggH77299qyJAhAfPnzJmjTZs2aePGjdq5c6eKioo0ceJEe/nFixeVkpKiyspK7dmzR6+88ooyMjK0aNEiu01BQYFSUlI0evRo5eXlafbs2Zo2bZq2bdsWtP0DAAAtm+OB6MyZM5o8ebL++7//W9dcc4093+/3a82aNVqxYoXGjBmjESNGaO3atdqzZ4/27t0rSXr33Xd17Ngxvfrqqxo2bJgmTJigJ554Qunp6aqsrJQkrV69WvHx8Xr66ac1aNAgzZw5U//wD/+glStXOrK/AACg5XE8EKWlpSklJUVJSUkB83Nzc3X+/PmA+QMHDlTv3r2Vk5MjScrJydHgwYMVExNjt0lOTpZlWTp69Kjd5tJtJycn29uoS0VFhSzLCpgAAEDb1cHJb75+/XodPHhQBw4cqLWsuLhYoaGhioqKCpgfExOj4uJiu03NMFS9vHrZ5dpYlqVz584pIiKi1vdetmyZHn/88UbvFwAAaF0c6yE6ceKEHnnkEb322msKDw93qow6LViwQH6/355OnDjhdEkAAKAZORaIcnNzVVpaquHDh6tDhw7q0KGDdu7cqeeee04dOnRQTEyMKisrVVZWFrBeSUmJYmNjJUmxsbG17jqr/nylNl6vt87eIUkKCwuT1+sNmAAAQNvlWCAaO3asDh8+rLy8PHu65ZZbNHnyZPvrkJAQZWVl2evk5+ersLBQPp9PkuTz+XT48GGVlpbabTIzM+X1epWQkGC3qbmN6jbV2wAAAHBsDFGXLl100003Bczr1KmTunXrZs+fOnWq5s6dq65du8rr9WrWrFny+XwaOXKkJGncuHFKSEjQfffdp+XLl6u4uFgLFy5UWlqawsLCJEnTp0/XCy+8oEcffVQPPvigsrOztWHDBm3ZsiW4OwwAAFosRwdVX8nKlSvVrl07paamqqKiQsnJyXrxxRft5e3bt9fmzZs1Y8YM+Xw+derUSVOmTNHSpUvtNvHx8dqyZYvmzJmjZ599Vj179tRLL72k5ORkJ3YJAAC0QC0qEO3YsSPgc3h4uNLT05Wenl7vOn369NE777xz2e2OGjVKhw4daooSAQBAG+T4c4gAAACcRiBCUBhj5Pf7ZYxxuhQAAGohECEoLMvSpBWbeOo3AKBFIhAhaEIiOjldAgAAdSIQAQAA1yMQAQAA1yMQAQAA1yMQAQAA1yMQAQAA1yMQAQAA1yMQAQAA1yMQAeJJ2gDgdgQiQDxJGwDcjkAE/B+epA0A7kUgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArtfB6QLQthljZFmWjDFOlwIAQL3oIUKzsixLk1ZskmVZTpcCAEC9CERodiERnZwuAQCAyyIQAQAA1yMQAQAA1yMQAQAA1yMQAQAA1yMQAQAA1yMQAQAA1yMQAQAA1yMQAQAA12tUIOrXr5+++uqrWvPLysrUr1+/71wUAABAMDUqEH322We6ePFirfkVFRX68ssvv3NRAAAAwdSgl7v+4Q9/sL/etm2bIiMj7c8XL15UVlaW+vbt22TFAQAABEODAtFdd90lSfJ4PJoyZUrAspCQEPXt21dPP/10kxUHAAAQDA0KRFVVVZKk+Ph4HThwQN27d2+WogAAAIKpQYGoWkFBQVPXAQAA4JhGBSJJysrKUlZWlkpLS+2eo2ovv/zydy4MAAAgWBoViB5//HEtXbpUt9xyi3r06CGPx9PUdQEAAARNowLR6tWrlZGRofvuu6+p6wEAAAi6Rj2HqLKyUn/3d3/X1LUAAAA4olGBaNq0aVq3bl1T1wIAAOCIRl0yKy8v1+9+9ztt375dQ4YMUUhISMDyFStWNElxgBOMMbIsS16vl/FxAOASjQpEH374oYYNGyZJOnLkSMAy/gFBa2dZliat2KTX594R8DR2AEDb1ahLZu+99169U3Z29lVvZ9WqVRoyZIi8Xq+8Xq98Pp/++Mc/2svLy8uVlpambt26qXPnzkpNTVVJSUnANgoLC5WSkqKOHTsqOjpa8+bN04ULFwLa7NixQ8OHD1dYWJj69++vjIyMxuw2XCQkopPTJQAAgqhRgaip9OzZU08++aRyc3P1wQcfaMyYMbrzzjt19OhRSdKcOXO0adMmbdy4UTt37lRRUZEmTpxor3/x4kWlpKSosrJSe/bs0SuvvKKMjAwtWrTIblNQUKCUlBSNHj1aeXl5mj17tqZNm6Zt27YFfX8BAEDL1KhLZqNHj77spbGr7SW64447Aj7/5je/0apVq7R371717NlTa9as0bp16zRmzBhJ0tq1azVo0CDt3btXI0eO1Lvvvqtjx45p+/btiomJ0bBhw/TEE09o/vz5WrJkiUJDQ7V69WrFx8fb71gbNGiQdu/erZUrVyo5Obkxu4/LYPwNAKA1alQP0bBhwzR06FB7SkhIUGVlpQ4ePKjBgwc3qpCLFy9q/fr1Onv2rHw+n3Jzc3X+/HklJSXZbQYOHKjevXsrJydHkpSTk6PBgwcrJibGbpOcnCzLsuxeppycnIBtVLep3kZdKioqZFlWwISrUz3+hmMGAGhNGtVDtHLlyjrnL1myRGfOnGnQtg4fPiyfz6fy8nJ17txZb775phISEpSXl6fQ0FBFRUUFtI+JiVFxcbEkqbi4OCAMVS+vXna5NpZl6dy5c4qIiKhV07Jly/T44483aD/wLcbfAABamyYdQ3Tvvfc2+D1mAwYMUF5envbt26cZM2ZoypQpOnbsWFOW1WALFiyQ3++3pxMnTjhaDwAAaF6NfrlrXXJychQeHt6gdUJDQ9W/f39J0ogRI3TgwAE9++yzmjRpkiorK1VWVhbQS1RSUqLY2FhJUmxsrPbv3x+wveq70Gq2ufTOtJKSEnm93jp7hyQpLCxMYWFhDdoPAADQejUqENW800v6ZiDtyZMn9cEHH+ixxx77TgVVVVWpoqJCI0aMUEhIiLKyspSamipJys/PV2FhoXw+nyTJ5/PpN7/5jUpLSxUdHS1JyszMlNfrVUJCgt3mnXfeCfgemZmZ9jYAAAAaFYgufVhdu3btNGDAAC1dulTjxo276u0sWLBAEyZMUO/evXX69GmtW7dOO3bs0LZt2xQZGampU6dq7ty56tq1q7xer2bNmiWfz6eRI0dKksaNG6eEhATdd999Wr58uYqLi7Vw4UKlpaXZPTzTp0/XCy+8oEcffVQPPvigsrOztWHDBm3ZsqUxuw4AANqgRgWitWvXNsk3Ly0t1f3336+TJ08qMjJSQ4YM0bZt2/SjH/1I0jeDt9u1a6fU1FRVVFQoOTlZL774or1++/bttXnzZs2YMUM+n0+dOnXSlClTtHTpUrtNfHy8tmzZojlz5ujZZ59Vz5499dJLL3HLPQAAsH2nMUS5ubn66KOPJEk33nijbr755gatv2bNmssuDw8PV3p6utLT0+tt06dPn1qXxC41atQoHTp0qEG1AQAA92hUICotLdXdd9+tHTt22AOey8rKNHr0aK1fv17XXnttU9YIAADQrBp12/2sWbN0+vRpHT16VKdOndKpU6d05MgRWZalX/3qV01dIwAAQLNqVA/R1q1btX37dg0aNMiel5CQoPT09AYNqgYAAGgJGtVDVFVVpZCQkFrzQ0JCVFVV9Z2LAgAACKZGBaIxY8bokUceUVFRkT3vyy+/1Jw5czR27NgmKw4AACAYGhWIXnjhBVmWpb59++q6667Tddddp/j4eFmWpeeff76pawQAAGhWjRpD1KtXLx08eFDbt2/Xxx9/LEkaNGhQrbfKAwAAtAYN6iHKzs5WQkKCLMuSx+PRj370I82aNUuzZs3SrbfeqhtvvFHvv/9+c9UKAADQLBoUiJ555hk99NBD8nq9tZZFRkbql7/8pVasWNFkxQEAAARDgwLRn//8Z40fP77e5ePGjVNubu53LgoAACCYGhSISkpK6rzdvlqHDh30l7/85TsXBQAAEEwNCkTf+973dOTIkXqXf/jhh+rRo8d3LgoAACCYGhSIfvzjH+uxxx5TeXl5rWXnzp3T4sWL9ZOf/KTJigMAAAiGBt12v3DhQr3xxhu64YYbNHPmTA0YMECS9PHHHys9PV0XL17Uv//7vzdLoQAAAM2lQYEoJiZGe/bs0YwZM7RgwQIZYyRJHo9HycnJSk9PV0xMTLMUCgSbMUZ+v1+S5PV65fF4HK4IANBcGvxgxj59+uidd97R3/72Nx0/flzGGF1//fW65pprmqM+wDGWZSlt3Td3Tb46Y4wiIyMdrggA0Fwa9aRqSbrmmmt06623NmUtQIsTEtHZ6RIAAEHQqHeZAQAAtCUEIgAA4HoEIgAA4HoEIgAA4HoEIgAA4HoEIgAA4HoEIgAA4HoEIgAA4HqNfjAjUJMxRpZl2a9zAQCgNaGHCE3CsixNWrFJlmU5XQoAAA1GIEKTCYno5HQJAAA0CoEIAAC4HoEIAAC4HoEIAAC4HoEIAAC4HoEIAAC4HoEIAAC4HoEIAAC4HoEIAAC4HoEIAAC4HoEIAAC4HoEIAAC4HoEIAAC4HoEIAAC4HoEIAAC4HoEIuArGGPn9fhljnC4FANAMCETAVbAsS5NWbJJlWU6XAgBoBgQi4CqFRHRyugQAQDMhEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANdzNBAtW7ZMt956q7p06aLo6Gjdddddys/PD2hTXl6utLQ0devWTZ07d1ZqaqpKSkoC2hQWFiolJUUdO3ZUdHS05s2bpwsXLgS02bFjh4YPH66wsDD1799fGRkZzb17rsADCwEAbYGjgWjnzp1KS0vT3r17lZmZqfPnz2vcuHE6e/as3WbOnDnatGmTNm7cqJ07d6qoqEgTJ060l1+8eFEpKSmqrKzUnj179MorrygjI0OLFi2y2xQUFCglJUWjR49WXl6eZs+erWnTpmnbtm1B3d+2iAcWAgDagg5OfvOtW7cGfM7IyFB0dLRyc3N1++23y+/3a82aNVq3bp3GjBkjSVq7dq0GDRqkvXv3auTIkXr33Xd17Ngxbd++XTExMRo2bJieeOIJzZ8/X0uWLFFoaKhWr16t+Ph4Pf3005KkQYMGaffu3Vq5cqWSk5ODvt9tDQ8sBAC0di1qDJHf75ckde3aVZKUm5ur8+fPKykpyW4zcOBA9e7dWzk5OZKknJwcDR48WDExMXab5ORkWZalo0eP2m1qbqO6TfU2LlVRUSHLsgImAADQdrWYQFRVVaXZs2fr+9//vm666SZJUnFxsUJDQxUVFRXQNiYmRsXFxXabmmGoenn1ssu1sSxL586dq1XLsmXLFBkZaU+9evVqkn0EAAAtU4sJRGlpaTpy5IjWr1/vdClasGCB/H6/PZ04ccLpkgAAQDNydAxRtZkzZ2rz5s3atWuXevbsac+PjY1VZWWlysrKAnqJSkpKFBsba7fZv39/wPaq70Kr2ebSO9NKSkrk9XoVERFRq56wsDCFhYU1yb4BAICWz9EeImOMZs6cqTfffFPZ2dmKj48PWD5ixAiFhIQoKyvLnpefn6/CwkL5fD5Jks/n0+HDh1VaWmq3yczMlNfrVUJCgt2m5jaq21RvAwAAuJujPURpaWlat26d3n77bXXp0sUe8xMZGamIiAhFRkZq6tSpmjt3rrp27Sqv16tZs2bJ5/Np5MiRkqRx48YpISFB9913n5YvX67i4mItXLhQaWlpdi/P9OnT9cILL+jRRx/Vgw8+qOzsbG3YsEFbtmxxbN8BAEDL4WgP0apVq+T3+zVq1Cj16NHDnl5//XW7zcqVK/WTn/xEqampuv322xUbG6s33njDXt6+fXtt3rxZ7du3l8/n07333qv7779fS5cutdvEx8dry5YtyszM1NChQ/X000/rpZde4pZ7AAAgyeEeoqt5unF4eLjS09OVnp5eb5s+ffronXfeuex2Ro0apUOHDjW4RgAA0Pa1mLvMAAAAnEIgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAhrAGCO/339Vj4wAALQeBCKgASzL0qQVm2RZltOlAACaEIEIDeb2XpKQiE5OlwAAaGIEIjQYvSQAgLaGQIRGoZcEANCWEIgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYhwVYwx8vv9MsY4XUqLwnEBgLaBQISrYlmWJq3YJMuynC6lReG4AEDbQCDCVQuJ6OR0CS0SxwUAWj8CEQAAcD0CEQAAcD0CEQAAcD0CEerFHVQAALcgEKFe3EEFAHALAhEuizuoAABuQCACAACuRyACAACuRyACAACuRyACAACuRyACAACuRyACAACuRyACAACuRyACAACuRyACAACuRyACAACuRyBCLbzUteE4ZgDQuhGIUAsvdW04jhkAtG4EItSJl7o2HMcMAFovAhEAAHA9AhEAAHA9AhEAAHA9RwPRrl27dMcddyguLk4ej0dvvfVWwHJjjBYtWqQePXooIiJCSUlJ+uSTTwLanDp1SpMnT5bX61VUVJSmTp2qM2fOBLT58MMP9cMf/lDh4eHq1auXli9f3ty7BgAAWhFHA9HZs2c1dOhQpaen17l8+fLleu6557R69Wrt27dPnTp1UnJyssrLy+02kydP1tGjR5WZmanNmzdr165devjhh+3llmVp3Lhx6tOnj3Jzc/XUU09pyZIl+t3vftfs+wcAAFqHDk5+8wkTJmjChAl1LjPG6JlnntHChQt15513SpL+53/+RzExMXrrrbd0991366OPPtLWrVt14MAB3XLLLZKk559/Xj/+8Y/1X//1X4qLi9Nrr72myspKvfzyywoNDdWNN96ovLw8rVixIiA4AQAA92qxY4gKCgpUXFyspKQke15kZKQSExOVk5MjScrJyVFUVJQdhiQpKSlJ7dq10759++w2t99+u0JDQ+02ycnJys/P19/+9rc6v3dFRYUsywqYAABA29ViA1FxcbEkKSYmJmB+TEyMvay4uFjR0dEByzt06KCuXbsGtKlrGzW/x6WWLVumyMhIe+rVq9d33yEAANBitdhA5KQFCxbI7/fb04kTJ5wuqdlVv3qC108AANzI0TFElxMbGytJKikpUY8ePez5JSUlGjZsmN2mtLQ0YL0LFy7o1KlT9vqxsbEqKSkJaFP9ubrNpcLCwhQWFtYk+9FaWJale1dlS5LSfz7C4WoAAAiuFttDFB8fr9jYWGVlZdnzLMvSvn375PP5JEk+n09lZWXKzc2122RnZ6uqqkqJiYl2m127dun8+fN2m8zMTA0YMEDXXHNNkPamdQiJ6KyQiM5OlwEAQNA5GojOnDmjvLw85eXlSfpmIHVeXp4KCwvl8Xg0e/Zs/cd//If+8Ic/6PDhw7r//vsVFxenu+66S5I0aNAgjR8/Xg899JD279+vP/3pT5o5c6buvvtuxcXFSZJ+/vOfKzQ0VFOnTtXRo0f1+uuv69lnn9XcuXMd2msAANDSOHrJ7IMPPtDo0aPtz9UhZcqUKcrIyNCjjz6qs2fP6uGHH1ZZWZl+8IMfaOvWrQoPD7fXee211zRz5kyNHTtW7dq1U2pqqp577jl7eWRkpN59912lpaVpxIgR6t69uxYtWsQt9wAAwOZoIBo1atRlB/B6PB4tXbpUS5curbdN165dtW7dust+nyFDhuj9999vdJ0AAKBta7FjiAAAAIKFQAQ0sepHGPD4AgBoPQhEQBOzLEuTVmziCecA0IoQiIBmEBLRyekSAAANQCACAACuRyACAACuRyACAACuRyACAACuRyByMW4PBwDgGwQiF+P2cAAAvkEgcjluD28+9MABQOtBIAKaCT1wANB6EIiAZkQPHAC0DgQiAADgegQiAADgeh2cLgDBZ4yRZVkM9gUA4P/QQ+RCDPYFACAQgcilGOwLAMC3uGQGBEH1ZUpJ8nq98ng8DlcEAKiJHiIgCCzL0r2rsnXvqmwuVQJAC0QPERAkIRGdnS4BAFAPeogAAIDrEYgAAIDrEYgAAIDrEYhcgjevAwBQPwKRS/AwRgAA6kcgchEexggAQN0IRECQcfkSAFoeAhEQZFy+BICWh0AEOIDLlwDQsvCk6jau+h1aXJ4BAKB+9BC1cVyeAQDgyghELsDlmZap5uBqBloDgLMIRIBDavbe0ZMHAM4iEAEOqtl7V/01vUUAEHwEIqCFobcIAIKPQAS0QIz7AoDgIhABAADXIxC1MYw/aVv4+wSA4CAQtTGMP2lbmvLvk3AFAPUjELVBjD9pWxr793lpACIsA0D9CERAK9CY3p26AlBIRCd6igCgDgQioBW4Uu9OfU+9rqt3iZ4iAKiNQAS0EjV7dy4NP36/v0FPveayKgAEIhABrYhlWbp3VbbuXZVdK/zU9dTry7k0XAGAm3VwugA0DWOMLMviHzYXCInofMnnxvX2WJaltHW5kqRXZ4xRZGTkd64NAForeojaCMaFoDFCIjrXClgA4EYEojaEcSEAADQOl8xaserLZNVfA41VPZ7I6/XK4/E4XQ4ABB09RK3YpQNsgcaqecmVwdYA3IgeolaO8R9oKtWXXKuDtiT9v+mj5fF41KVLF50+fdr+U1K9vUnVPZf0NgFoTVzVQ5Senq6+ffsqPDxciYmJ2r9/v9MlXZX6nj3D/97RXKoHW1f3HH3xxRf2nzV7JavPxaqqKvscrX4mEr1MAFoT1wSi119/XXPnztXixYt18OBBDR06VMnJySotLXW6tCu63LNngOZW3XP07Z/f3plWMzDVPEdDIjrVeRmuZqCvGaKqv67+szpEXdqWcAWgubgmEK1YsUIPPfSQHnjgASUkJGj16tXq2LGjXn75ZadLq1fgKxgCb4/mjjK0FHUFpUuX1QxHdYWomj1QNcP+pT1UdfVK1Reeai6v79Um9a3T1OGLXl2g5XPFGKLKykrl5uZqwYIF9rx27dopKSlJOTk5tdpXVFSooqLC/uz3+yWp2Xpkqrd/KcuylPbf2/Xk3Yn6+m/f9GR98cUXkqRzZX9VUVGRPb+oqIs971zZX/XFF1/Y//hcOr/m+jXnXW5b1evU93V128Z+/7ra1rV/V/P9G3Os6ttmSzy+9e1fUx7f+mr9Lsf3QsW5gK+Liop0vvzr/1unyJ5X3a665kvnS7J/Lv51/T6lP5Qkr9cb8PPyr+v3BSyvXqe+r2uus/Ctw5KkZ+/7O3m9XjWF6tqqawVQW3M8HLZBd2IbF/jyyy+NJLNnz56A+fPmzTO33XZbrfaLFy82kpiYmJiYmJjawHTixIkrZgVX9BA11IIFCzR37lz7c1VVlU6dOqWQkBD17t1bJ06ccPX/8izLUq9evVx/HCSORU0ci29wHL7FsfgWx+JbwTwWxhidPn1acXFxV2zrikDUvXt3tW/fXiUlJQHzS0pKFBsbW6t9WFiYwsLCAuZFRUXZXW9er9f1J7TEcaiJY/EtjsU3OA7f4lh8i2PxrWAdi6u9FOeKQdWhoaEaMWKEsrKy7HlVVVXKysqSz+dzsDIAANASuKKHSJLmzp2rKVOm6JZbbtFtt92mZ555RmfPntUDDzzgdGkAAMBhrglEkyZN0l/+8hctWrRIxcXFGjZsmLZu3aqYmJir3kZYWJgWL15c63Ka23AcvsWx+BbH4hsch29xLL7FsfhWSz0WHmN4MAYAAHA3V4whAgAAuBwCEQAAcD0CEQAAcD0CEQAAcD0C0VVKT09X3759FR4ersTERO3fv9/pkprdsmXLdOutt6pLly6Kjo7WXXfdpfz8/IA2o0aNksfjCZimT5/uUMXNY8mSJbX2ceDAgfby8vJypaWlqVu3burcubNSU1NrPQS0rejbt2+tY+HxeJSWliapbZ8Pu3bt0h133KG4uDh5PB699dZbAcuNMVq0aJF69OihiIgIJSUl6ZNPPgloc+rUKU2ePFler1dRUVGaOnWqzpw5E8S9+O4udxzOnz+v+fPna/DgwerUqZPi4uJ0//33q6ioKGAbdZ1HTz75ZJD35Lu70jnxi1/8otZ+jh8/PqBNWzgnpCsfi7p+b3g8Hj311FN2G6fPCwLRVXj99dc1d+5cLV68WAcPHtTQoUOVnJys0tJSp0trVjt37lRaWpr27t2rzMxMnT9/XuPGjdPZs2cD2j300EM6efKkPS1fvtyhipvPjTfeGLCPu3fvtpfNmTNHmzZt0saNG7Vz504VFRVp4sSJDlbbfA4cOBBwHDIzMyVJ//iP/2i3aavnw9mzZzV06FClp6fXuXz58uV67rnntHr1au3bt0+dOnVScnKyysvL7TaTJ0/W0aNHlZmZqc2bN2vXrl16+OGHg7ULTeJyx+Hrr7/WwYMH9dhjj+ngwYN64403lJ+fr5/+9Ke12i5dujTgPJk1a1Ywym9SVzonJGn8+PEB+/n73/8+YHlbOCekKx+Lmsfg5MmTevnll+XxeJSamhrQztHzoknentrG3XbbbSYtLc3+fPHiRRMXF2eWLVvmYFXBV1paaiSZnTt32vP+/u//3jzyyCPOFRUEixcvNkOHDq1zWVlZmQkJCTEbN26053300UdGksnJyQlShc555JFHzHXXXWeqqqqMMe44H4wxRpJ588037c9VVVUmNjbWPPXUU/a8srIyExYWZn7/+98bY4w5duyYkWQOHDhgt/njH/9oPB6P+fLLL4NWe1O69DjUZf/+/UaS+fzzz+15ffr0MStXrmze4oKsrmMxZcoUc+edd9a7Tls8J4y5uvPizjvvNGPGjAmY5/R5QQ/RFVRWVio3N1dJSUn2vHbt2ikpKUk5OTkOVhZ8fr9fktS1a9eA+a+99pq6d++um266SQsWLNDXX3/tRHnN6pNPPlFcXJz69eunyZMnq7CwUJKUm5ur8+fPB5wfAwcOVO/evdv8+VFZWalXX31VDz74oDwejz3fDefDpQoKClRcXBxwHkRGRioxMdE+D3JychQVFaVbbrnFbpOUlKR27dpp3759Qa85WPx+vzwej6KiogLmP/nkk+rWrZtuvvlmPfXUU7pw4YIzBTazHTt2KDo6WgMGDNCMGTP01Vdf2cvcek6UlJRoy5Ytmjp1aq1lTp4XrnlSdWP99a9/1cWLF2s90TomJkYff/yxQ1UFX1VVlWbPnq3vf//7uummm+z5P//5z9WnTx/FxcXpww8/1Pz585Wfn6833njDwWqbVmJiojIyMjRgwACdPHlSjz/+uH74wx/qyJEjKi4uVmhoaK1f9jExMSouLnam4CB56623VFZWpl/84hf2PDecD3Wp/ruu6/dE9bLi4mJFR0cHLO/QoYO6du3aZs+V8vJyzZ8/X/fcc0/ASzx/9atfafjw4eratav27NmjBQsW6OTJk1qxYoWD1Ta98ePHa+LEiYqPj9enn36qf/u3f9OECROUk5Oj9u3bu/KckKRXXnlFXbp0qTW0wOnzgkCEq5KWlqYjR44EjJ2RFHCte/DgwerRo4fGjh2rTz/9VNddd12wy2wWEyZMsL8eMmSIEhMT1adPH23YsEEREREOVuasNWvWaMKECYqLi7PnueF8wNU5f/68/umf/knGGK1atSpg2dy5c+2vhwwZotDQUP3yl7/UsmXLWtzrHL6Lu+++2/568ODBGjJkiK677jrt2LFDY8eOdbAyZ7388suaPHmywsPDA+Y7fV5wyewKunfvrvbt29e6a6ikpESxsbEOVRVcM2fO1ObNm/Xee++pZ8+el22bmJgoSTp+/HgwSnNEVFSUbrjhBh0/flyxsbGqrKxUWVlZQJu2fn58/vnn2r59u6ZNm3bZdm44HyTZf9eX+z0RGxtb60aMCxcu6NSpU23uXKkOQ59//rkyMzMDeofqkpiYqAsXLuizzz4LToEO6devn7p3727/PLjpnKj2/vvvKz8//4q/O6TgnxcEoisIDQ3ViBEjlJWVZc+rqqpSVlaWfD6fg5U1P2OMZs6cqTfffFPZ2dmKj4+/4jp5eXmSpB49ejRzdc45c+aMPv30U/Xo0UMjRoxQSEhIwPmRn5+vwsLCNn1+rF27VtHR0UpJSblsOzecD5IUHx+v2NjYgPPAsizt27fPPg98Pp/KysqUm5trt8nOzlZVVZUdHNuC6jD0ySefaPv27erWrdsV18nLy1O7du1qXT5qa7744gt99dVX9s+DW86JmtasWaMRI0Zo6NChV2wb9PPCseHcrcj69etNWFiYycjIMMeOHTMPP/ywiYqKMsXFxU6X1qxmzJhhIiMjzY4dO8zJkyft6euvvzbGGHP8+HGzdOlS88EHH5iCggLz9ttvm379+pnbb7/d4cqb1r/8y7+YHTt2mIKCAvOnP/3JJCUlme7du5vS0lJjjDHTp083vXv3NtnZ2eaDDz4wPp/P+Hw+h6tuPhcvXjS9e/c28+fPD5jf1s+H06dPm0OHDplDhw4ZSWbFihXm0KFD9t1TTz75pImKijJvv/22+fDDD82dd95p4uPjzblz5+xtjB8/3tx8881m3759Zvfu3eb6668399xzj1O71CiXOw6VlZXmpz/9qenZs6fJy8sL+L1RUVFhjDFmz549ZuXKlSYvL898+umn5tVXXzXXXnutuf/++x3es4a73LE4ffq0+fWvf21ycnJMQUGB2b59uxk+fLi5/vrrTXl5ub2NtnBOGHPlnw9jjPH7/aZjx45m1apVtdZvCecFgegqPf/886Z3794mNDTU3HbbbWbv3r1Ol9TsJNU5rV271hhjTGFhobn99ttN165dTVhYmOnfv7+ZN2+e8fv9zhbexCZNmmR69OhhQkNDzfe+9z0zadIkc/z4cXv5uXPnzD//8z+ba665xnTs2NH87Gc/MydPnnSw4ua1bds2I8nk5+cHzG/r58N7771X58/DlClTjDHf3Hr/2GOPmZiYGBMWFmbGjh1b6xh99dVX5p577jGdO3c2Xq/XPPDAA+b06dMO7E3jXe44FBQU1Pt747333jPGGJObm2sSExNNZGSkCQ8PN4MGDTL/+Z//GRASWovLHYuvv/7ajBs3zlx77bUmJCTE9OnTxzz00EO1/iPdFs4JY67882GMMb/97W9NRESEKSsrq7V+SzgvPMYY06xdUAAAAC0cY4gAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDrEYgAAIDr/X/QGHP2xlbJrwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データの辞書を作る\n",
        "\n"
      ],
      "metadata": {
        "id": "PQmTlNyk2sHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. トークン化\n",
        "  - 単語(token)に分割する(tokenize)\n",
        "  - torchtext.data.uHls.get_tokenizerを使用する\n",
        "  - get_tokenizer(‘basic_english’)\n",
        "2. イテレータ作成\n",
        "  - 各単語(token)を返すイテレータを作る\n",
        "3. 辞書作成\n",
        "  - torchtext.vacab.build_vocab_from_iteratorを使用する\n",
        "  - iterator: 単語(token)を返すイテレータ\n",
        "  - min_freq: 辞書に登録する単語の最小頻度 (デフォルトは1)\n",
        "  - specials: \"unkown\"などの特別なtokenを予約する\n",
        "  - vocab[‘word’]のようにしてその単語のindexを取得する\n",
        "  - .get_itos() で全tokenのリストを取得する\n",
        "  - .set_default_index(index)で辞書にない単語のデフォルトのindexを指定する"
      ],
      "metadata": {
        "id": "qwmg65S22xdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# トークン化\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')"
      ],
      "metadata": {
        "id": "gAP6pJKu09l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 単語をトークン化できる\n",
        "tokenizer('I am a student.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuNBKrt86u1X",
        "outputId": "1620684a-99f0-414b-86d5-3112ede907c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'a', 'student', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# イテレータ作成\n",
        "def yield_tokens(data):\n",
        "    for _, text in data:\n",
        "        yield tokenizer(text)"
      ],
      "metadata": {
        "id": "fLWo8UNl7Vuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(yield_tokens(data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDlJrH8k7iBD",
        "outputId": "6e0f1915-d80b-4c3b-e01c-97170709e602",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wall',\n",
              " 'st',\n",
              " '.',\n",
              " 'bears',\n",
              " 'claw',\n",
              " 'back',\n",
              " 'into',\n",
              " 'the',\n",
              " 'black',\n",
              " '(',\n",
              " 'reuters',\n",
              " ')',\n",
              " 'reuters',\n",
              " '-',\n",
              " 'short-sellers',\n",
              " ',',\n",
              " 'wall',\n",
              " 'street',\n",
              " \"'\",\n",
              " 's',\n",
              " 'dwindling\\\\band',\n",
              " 'of',\n",
              " 'ultra-cynics',\n",
              " ',',\n",
              " 'are',\n",
              " 'seeing',\n",
              " 'green',\n",
              " 'again',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 辞書作成\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# unknownをspcialに追加\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_data), specials=[\"<unk>\"])\n",
        "# 辞書にない単語のデフォルトのindexを指定する\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "HHGTQa466z3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab辞書から'hello'の単語のindexを返す\n",
        "vocab['hello']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWQhU2eM8WYN",
        "outputId": "0d7e50df-0f38-4e04-a68b-c931527b32cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14923"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 存在しない単語のindexも同様に0\n",
        "vocab['xxxxxxxxxxx']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPEwefRb8kCo",
        "outputId": "d43d3bc0-c1e1-4fee-9a23-21d9d93aed34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specials=<unk>を指定するとindexは0になる\n",
        "vocab['<unk>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8C4xhv-8r-L",
        "outputId": "be4b79e9-eeb3-4a2c-f39f-0387008c8700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# indexから逆引き\n",
        "vocab.get_itos()[14923]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PWnPwfAy9wSM",
        "outputId": "8390e432-fead-4e10-d781-0ee875780416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoaderを作成"
      ],
      "metadata": {
        "id": "clcCn5CA1Tcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- DataLoaderを作成\n",
        "  - DataLoader: 手元のデータをバッチごとに区切ってイテレーションしてくれるもの\n",
        "  - バッチサイズ=8\n",
        "  - Collate_fn: バッチ単位で必要な処理(関数)\n",
        "    - バッチ単位でpaddingを行う\n",
        "    - labelを1-4ではなく、0-3に変更する"
      ],
      "metadata": {
        "id": "dK5zvfc_1XSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCcqMaLU2m_N",
        "outputId": "e42089dd-de66-48c7-c679-aeec30995195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2,\n",
              "  'SECOND LOOKSnapshots from the latest in college football The boys of Pi Kappa Phi better look out. Mississippi State pulls off the SEC stunner of this Millennium, beating Ron Zook and Florida 38-31.'),\n",
              " (1,\n",
              "  'Summit of French-Speaking Countries Condemns Ivory Coast Leaders at a summit in Burkina Faso of mostly French-speaking nations have condemned authorities in divided Ivory Coast for resuming hostilities in the rebel-held north earlier this month.'),\n",
              " (4,\n",
              "  'Lost faith in Internet Explorer? Try another browser Microsoft has won the browser wars, but a battle is raging for the runner-up spot and one of the contenders has recently been refreshed.')]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch: [(label, text), (label, text),...,]\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_batch(batch):\n",
        "  # label, textに対する処理\n",
        "  label_list = []\n",
        "  text_list = []\n",
        "  for label, text in batch:\n",
        "      # label: 1-4 -> 0~3\n",
        "      label_list.append(label - 1)\n",
        "      # tokenize: [\"I am a student\"] - >[\"I\", \"am\", \"a\", \"student\"] -> (ex.)[4, 1, 6, 7]\n",
        "      text_list.append(torch.tensor([vocab[token] for token in tokenizer(text)]))\n",
        "\n",
        "  # padding\n",
        "  label_list = torch.tensor(label_list)\n",
        "  text_list = pad_sequence(text_list, batch_first=True, padding_value=0)\n",
        "  return label_list, text_list"
      ],
      "metadata": {
        "id": "AzedA9UW3CNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 例\n",
        "label_list, text_list = collate_batch(train_data[:1])\n",
        "print(label_list)\n",
        "print(text_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIKR8_RW5pLQ",
        "outputId": "1f3e8d58-4fe3-483d-b28d-b8d8dceb65af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1])\n",
            "tensor([[  144, 25474,    29,     2,   306,     7,   956,   329,     2,  5780,\n",
            "             6, 16111, 24933, 27357,   614,   712,    61,     1,  4005,   138,\n",
            "          4520,   118,     2,  1585, 17035,     6,    50, 11705,     3,  1149,\n",
            "          2595,  4607,     8,   473, 10331,     1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 最長の文章は51単語\n",
        "text_list.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51dxwZEZ6bP9",
        "outputId": "709fca2f-b99e-4556-9b79-c1448cfa9bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 36])"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_data, batch_size=8, collate_fn=collate_batch, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=8, collate_fn=collate_batch, shuffle=False)"
      ],
      "metadata": {
        "id": "FVe9EBHF92V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am a student\"\n",
        "tokenizer(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UC169Yn4i-e",
        "outputId": "a0cf1217-127c-4235-80c1-afa1113b17db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'a', 'student']"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# バッチサイズ:8\n",
        "label, text = next(iter(train_loader))\n",
        "print(label)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7Xlm_eq4jbj",
        "outputId": "4d918b0c-206a-4c99-8b53-28831401cc76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 1, 2, 0, 1, 0, 1, 1])\n",
            "tensor([[ 4495, 12326,   822,  2012,    17, 11742,    12,     9, 15835, 12326,\n",
            "          8327,     2, 11742,  8327,   484,  3343,    22,  3516,     2,   977,\n",
            "            49,   734,  5207,     6,     2, 24912, 26449, 27455,     7,  2994,\n",
            "             3,    20,     6,   381,   188,   220,    40,   279,   231,   734,\n",
            "         15835, 12326,  3052,    19, 11742,     7,  1266,     3,    47,     6,\n",
            "           105,  3975,     4,    37,     7,  1194,  1539,  2347,     1],\n",
            "        [ 7908,  1357, 17089,     4,  1188,     5,  7966, 14612,  3917,     3,\n",
            "          5075,     1,    54,   672,  2996,  1838,  2290,  6083,  7908, 17089,\n",
            "             4,  1188,     5,  7966,     8, 14607,    32,  3805,  1819,     3,\n",
            "           968,    26,    55,     1,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 9931,  1115,  4343,   529,   910,  2340,     8,  9032,   660,  1481,\n",
            "          9931,    90,     1,    26,    57,    25,  1376,   636,    29,     2,\n",
            "           157,  2065,    18,   240,     2, 10026,    94,   180,     7,   620,\n",
            "             8,   397,     4,  1331,   585,   266,    24, 18748,    80,     3,\n",
            "           115,  6230,  1930,   527,   459,     1,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [   78,   156,     4,     2,  8846,   221,     5,   815,   358,  1786,\n",
            "           137,   686,   106,    19,     5,   187,  1111,  2174,     7,   828,\n",
            "            65,    73,     1,    30,  3429,   984,   290,    26,     2,  1786,\n",
            "          2830,  4046,    11,     2,  8392,   588,     7,     2,   944,     6,\n",
            "         13200,     3, 18257,  2796,     6,   221,     3,   354,     2,  4079,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 9136,  1857, 27956,    61,     3,   253,   363,   219,  2965,   606,\n",
            "          2499,  9136,     3, 28724,    15,    88,  2265,  1171,     4,  4085,\n",
            "            61,     2,   211,  5070,    17,   157,  9525,  2694,    19,    74,\n",
            "            81,    12,     9,   515,    19,     2,  4509,   153, 12078,     3,\n",
            "            25,  7076,     2,  9826,     6,    23,    21, 23640,  1308,    18,\n",
            "            34,  5244,     4,   238,  8899,     5, 23639,     0,     0],\n",
            "        [ 4748,  9236,   390,    12,     9, 26353,    36,  4215,    10,   642,\n",
            "           829,  2835,     3,   611,  1733,   390,  5056,   305, 20798,    39,\n",
            "            23,   315,  3830,    10,    56,    45,   141,     3,   105,  4349,\n",
            "            25,     6,  1234,    30,  2370,   408,     3,    26,    25, 16444,\n",
            "             2,   381,     4,   224,     2,   395,     4,     2,    96,   739,\n",
            "            10,    23,   640,     1,     0,     0,     0,     0,     0],\n",
            "        [ 4760,   615,  4998,  5885,  8227,  5885,     3,     2,   128,   498,\n",
            "          1937,  4760,     3,    33,    60,   439, 14220,   477,  6674,     4,\n",
            "          9833,  1975,   202,    64,   270,     7,     5,    86,  1510,     3,\n",
            "             2,  4760,   615,    26,    10,    57,     1,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  223,     7,  3091, 15428,  1623,   249,   712,    11,   314,  1623,\n",
            "           249,   743, 28742,   595,     2,  4198,    59,     7,   197,     6,\n",
            "           314,    10,   132,   104,     6,     2,  4230,     3,    17,    78,\n",
            "          1352,  1428,   204,   273,     8,   547,     1,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## word embedding matrixを作成"
      ],
      "metadata": {
        "id": "UMZUqxsZ79GW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- gensimのword2vecを使用\n",
        "  - GoogleNews-vectors-negative300.bin\n",
        "- tokenのindexに対してword embedding(size=(300,))を返すようなtenrosrを作成する\n",
        "  - word2vecの戻り値がnumpy arrayであることに注意\n",
        "- \"unk\"のベクトルは全word embeddingの平均を取る"
      ],
      "metadata": {
        "id": "_6eEABcf8Voq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# google drive のマウント\n",
        "from google.colab import drive\n",
        "drive_path = '/content/drive'\n",
        "drive.mount(drive_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExKKEDH47idw",
        "outputId": "38a978c4-20b1-4662-ad9b-1c1b1395ae18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gensimのword2vecを使用\n",
        "from gensim.models import KeyedVectors\n",
        "word2vec = KeyedVectors.load_word2vec_format(f'{drive_path}/MyDrive/models/GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "metadata": {
        "id": "3p99Gs8F9uXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 91202語ある\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRzc-IQL_4XC",
        "outputId": "6ca7b55a-7a9b-42ba-f370-8ea6fc0bbab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31918"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# unkownには，word2vecの全単語の平均のベクトルを適用する\n",
        "unk_vector = torch.from_numpy(np.mean(word2vec.vectors, axis=0))\n",
        "embedding_matrix = np.zeros((len(vocab), 300))  # まずベクトルを初期化する\n",
        "\n",
        "for i, word in enumerate(vocab.get_itos()):\n",
        "    if word in word2vec:\n",
        "        embedding_matrix[i] = torch.from_numpy(word2vec[word])  # 初期化したベクトルにvocabの単語のベクトルを代入\n",
        "    else:\n",
        "        embedding_matrix[i] = unk_vector  # unkであれば、単語の平均を代入"
      ],
      "metadata": {
        "id": "dNciimvh-Eal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# indexが2の単語は\"the\"\n",
        "print(vocab.get_itos()[2])\n",
        "\n",
        "# \"the\"の300次元のベクトル\n",
        "print(word2vec[vocab.get_itos()[2]].shape)\n",
        "# print(word2vec[vocab.get_itos()[2]])\n",
        "\n",
        "# embedding_matrixのindexにこのベクトルを代入する\n",
        "embedding_matrix = np.zeros((len(vocab), 300))  # まずベクトルを初期化する\n",
        "embedding_matrix[2] = torch.from_numpy(word2vec[vocab.get_itos()[2]])\n",
        "\n",
        "# 初期化したembedding_matrixにtheのベクトルが入っているのがわかる\n",
        "print(embedding_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2af3eCwEAgvS",
        "outputId": "bc37a10e-9990-47bf-a00e-b2c6a801389d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the\n",
            "(300,)\n",
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.08007812  0.10498047  0.04980469 ...  0.00366211  0.04760742\n",
            "  -0.06884766]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unkownには，word2vecの全単語の平均のベクトルを適用する\n",
        "print(word2vec.vectors.shape)\n",
        "print(np.mean(word2vec.vectors, axis=0).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJThcQ81AmYV",
        "outputId": "a1c8b815-f947-454f-9ea4-b6edc81d9c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3000000, 300)\n",
            "(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## トピック分類用のモデルを作成"
      ],
      "metadata": {
        "id": "vtBTKA0RGiBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- トピック分類用のmany-to-oneのRNNを作成する(前セクションの物を転用)\n",
        "  - embedding層\n",
        "    - nn.Embedding.from_pretrained()を使用して学習済みのword_embeddingを初期値として使用する(学習可能とする)"
      ],
      "metadata": {
        "id": "2hMTqyRUGou_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, embedding_matrix=None, num_layers=1, rnn_type='LSTM', bidirectional=False):\n",
        "\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "\n",
        "        # embedding layer追加 (vocab_size x embedding_dim)\n",
        "        if embedding_matrix is not None:\n",
        "            # embedding matrixで重みを初期化\n",
        "            self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        input_size = embedding_dim\n",
        "\n",
        "        if rnn_type == 'RNN':\n",
        "            self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        elif rnn_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        elif rnn_type == 'GRU':\n",
        "            self.rnn = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        else:\n",
        "            raise ValueError('Unsupported RNN type. Choose from [\"LSTM\", \"RNN\", \"GRU\", \"UGRNN\"]')\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size*self.num_directions, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output_seq, _ = self.rnn(x)\n",
        "        output_seq = output_seq[:, -1, :]\n",
        "        # output_seq: [batch_size, seq_len, hidden_size*num_directions]\n",
        "        out = self.fc(output_seq)\n",
        "        return out"
      ],
      "metadata": {
        "id": "dd4a54vnFAeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## トピック分類の学習ループ"
      ],
      "metadata": {
        "id": "uAbVhD9cAnce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習ループ\n",
        "def train(model, train_loader, val_loader, optimizer, criterion, num_epochs):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for i, (labels, sentences) in enumerate(train_loader):\n",
        "            sentences = sentences.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(sentences)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Average Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # 検証データを使用して検証エラーを計算\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        total_samples = 0\n",
        "        total_correct = 0\n",
        "        for labels, sentences in val_loader:\n",
        "            sentences = sentences.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(sentences)\n",
        "            # loss計算\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # accuracy計算\n",
        "            _, predicted = torch.max(outputs, dim=-1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.numel()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_accuracy = total_correct / total_samples\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "8zSbvvj9IY5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "num_classes = 4\n",
        "embedding_dim = 300\n",
        "hidden_size = 64\n",
        "output_size = num_classes\n",
        "learning_rate = 0.001\n",
        "num_epochs = 3\n",
        "num_layers = 1\n",
        "\n",
        "# モデル作成\n",
        "model = Model(vocab_size, embedding_dim, hidden_size, output_size, embedding_matrix=torch.tensor(embedding_matrix),\n",
        "              num_layers=num_layers, rnn_type='LSTM', bidirectional=True)\n",
        "\n",
        "# 損失関数とOptimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ZcERu2g_DSyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_loader, val_loader, optimizer, criterion, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "Pkx_770wDabj",
        "outputId": "927c95f5-24df-468c-9733-ee414bee9003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Input and parameter tensors are not the same dtype, found input tensor with Double and parameter tensor with Float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-145-a6e9815dd3c1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-141-c1eb6ba70b20>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-140-b038ebd21fa5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0moutput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# output_seq: [batch_size, seq_len, hidden_size*num_directions]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    880\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not the same dtype, found input tensor with Double and parameter tensor with Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ck5RyZcnDcEA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}