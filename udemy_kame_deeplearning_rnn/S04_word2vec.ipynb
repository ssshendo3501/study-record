{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7teq8g7FEnkH"
      },
      "source": [
        "# word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0vCxpz8EqPg"
      },
      "source": [
        "## Gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIRV5LtDBQB7"
      },
      "source": [
        "- pip install gensimでinstall\n",
        "- gensim.models.KeyedVectorsクラスを使用して学習済みのモデルでword embeddingする\n",
        "- 事前に学習済みのモデルファイルをDLする\n",
        "  - https://code.google.com/archive/p/word2vec/\n",
        "  - GoogleNewsの1000億語の単語を300次元にしたもの\n",
        "- .load_word2vec_format(filename)でモデルファイルをロード\n",
        "- .bin等のbinaryファイルの場合はbinary=Trueを指定する\n",
        "- インスタンスに対して[‘word’]の形でベクトルを取得\n",
        "- .most_similar(‘word‘, topn=10)で引数の単語に最も近い単語をtopn個(デフォルト10)をリストで返す\n",
        "- .similarity(‘word’, ’word2’)で二つの単語の類似度を返す"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnZaAfvNEXee"
      },
      "outputs": [],
      "source": [
        "# colabでは不要\n",
        "# !pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2S9sKzvEjAv"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvAonsvGE7Po",
        "outputId": "7172370b-56ed-453a-b2e9-b1c1209448c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# google drive のマウント\n",
        "from google.colab import drive\n",
        "drive_path = '/content/drive'\n",
        "drive.mount(drive_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S00cut31Ewbj"
      },
      "outputs": [],
      "source": [
        "# モデルファイルのロード\n",
        "word2vec = KeyedVectors.load_word2vec_format(f'{drive_path}/MyDrive/models/GoogleNews-vectors-negative300.bin', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0NVX9M7E6eK",
        "outputId": "267fe6a9-ffce-481e-adef-4550139543ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 1.07421875e-01 -2.01171875e-01  1.23046875e-01  2.11914062e-01\n",
            " -9.13085938e-02  2.16796875e-01 -1.31835938e-01  8.30078125e-02\n",
            "  2.02148438e-01  4.78515625e-02  3.66210938e-02 -2.45361328e-02\n",
            "  2.39257812e-02 -1.60156250e-01 -2.61230469e-02  9.71679688e-02\n",
            " -6.34765625e-02  1.84570312e-01  1.70898438e-01 -1.63085938e-01\n",
            " -1.09375000e-01  1.49414062e-01 -4.65393066e-04  9.61914062e-02\n",
            "  1.68945312e-01  2.60925293e-03  8.93554688e-02  6.49414062e-02\n",
            "  3.56445312e-02 -6.93359375e-02 -1.46484375e-01 -1.21093750e-01\n",
            " -2.27539062e-01  2.45361328e-02 -1.24511719e-01 -3.18359375e-01\n",
            " -2.20703125e-01  1.30859375e-01  3.66210938e-02 -3.63769531e-02\n",
            " -1.13281250e-01  1.95312500e-01  9.76562500e-02  1.26953125e-01\n",
            "  6.59179688e-02  6.93359375e-02  1.02539062e-02  1.75781250e-01\n",
            " -1.68945312e-01  1.21307373e-03 -2.98828125e-01 -1.15234375e-01\n",
            "  5.66406250e-02 -1.77734375e-01 -2.08984375e-01  1.76757812e-01\n",
            "  2.38037109e-02 -2.57812500e-01 -4.46777344e-02  1.88476562e-01\n",
            "  5.51757812e-02  5.02929688e-02 -1.06933594e-01  1.89453125e-01\n",
            " -1.16210938e-01  8.49609375e-02 -1.71875000e-01  2.45117188e-01\n",
            " -1.73828125e-01 -8.30078125e-03  4.56542969e-02 -1.61132812e-02\n",
            "  1.86523438e-01 -6.05468750e-02 -4.17480469e-02  1.82617188e-01\n",
            "  2.20703125e-01 -1.22558594e-01 -2.55126953e-02 -3.08593750e-01\n",
            "  9.13085938e-02  1.60156250e-01  1.70898438e-01  1.19628906e-01\n",
            "  7.08007812e-02 -2.64892578e-02 -3.08837891e-02  4.06250000e-01\n",
            " -1.01562500e-01  5.71289062e-02 -7.26318359e-03 -9.17968750e-02\n",
            " -1.50390625e-01 -2.55859375e-01  2.16796875e-01 -3.63769531e-02\n",
            "  2.24609375e-01  8.00781250e-02  1.56250000e-01  5.27343750e-02\n",
            "  1.50390625e-01 -1.14746094e-01 -8.64257812e-02  1.19140625e-01\n",
            " -7.17773438e-02  2.73437500e-01 -1.64062500e-01  7.29370117e-03\n",
            "  4.21875000e-01 -1.12792969e-01 -1.35742188e-01 -1.31835938e-01\n",
            " -1.37695312e-01 -7.66601562e-02  6.25000000e-02  4.98046875e-02\n",
            " -1.91406250e-01 -6.03027344e-02  2.27539062e-01  5.88378906e-02\n",
            " -3.24218750e-01  5.41992188e-02 -1.35742188e-01  8.17871094e-03\n",
            " -5.24902344e-02 -1.74713135e-03 -9.81445312e-02 -2.86865234e-02\n",
            "  3.61328125e-02  2.15820312e-01  5.98144531e-02 -3.08593750e-01\n",
            " -2.27539062e-01  2.61718750e-01  9.86328125e-02 -5.07812500e-02\n",
            "  1.78222656e-02  1.31835938e-01 -5.35156250e-01 -1.81640625e-01\n",
            "  1.38671875e-01 -3.10546875e-01 -9.71679688e-02  1.31835938e-01\n",
            " -1.16210938e-01  7.03125000e-02  2.85156250e-01  3.51562500e-02\n",
            " -1.01562500e-01 -3.75976562e-02  1.41601562e-01  1.42578125e-01\n",
            " -5.68847656e-02  2.65625000e-01 -2.09960938e-01  9.64355469e-03\n",
            " -6.68945312e-02 -4.83398438e-02 -6.10351562e-02  2.45117188e-01\n",
            " -9.66796875e-02  1.78222656e-02 -1.27929688e-01 -4.78515625e-02\n",
            " -7.26318359e-03  1.79687500e-01  2.78320312e-02 -2.10937500e-01\n",
            " -1.43554688e-01 -1.27929688e-01  1.73339844e-02 -3.60107422e-03\n",
            " -2.04101562e-01  3.63159180e-03 -1.19628906e-01 -6.15234375e-02\n",
            "  5.93261719e-02 -3.23486328e-03 -1.70898438e-01 -3.14941406e-02\n",
            " -8.88671875e-02 -2.89062500e-01  3.44238281e-02 -1.87500000e-01\n",
            "  2.94921875e-01  1.58203125e-01 -1.19628906e-01  7.61718750e-02\n",
            "  6.39648438e-02 -4.68750000e-02 -6.83593750e-02  1.21459961e-02\n",
            " -1.44531250e-01  4.54101562e-02  3.68652344e-02  3.88671875e-01\n",
            "  1.45507812e-01 -2.55859375e-01 -4.46777344e-02 -1.33789062e-01\n",
            " -1.38671875e-01  6.59179688e-02  1.37695312e-01  1.14746094e-01\n",
            "  2.03125000e-01 -4.78515625e-02  1.80664062e-02 -8.54492188e-02\n",
            " -2.48046875e-01 -3.39843750e-01 -2.83203125e-02  1.05468750e-01\n",
            " -2.14843750e-01 -8.74023438e-02  7.12890625e-02  1.87500000e-01\n",
            " -1.12304688e-01  2.73437500e-01 -3.26171875e-01 -1.77734375e-01\n",
            " -4.24804688e-02 -2.69531250e-01  6.64062500e-02 -6.88476562e-02\n",
            " -1.99218750e-01 -7.03125000e-02 -2.43164062e-01 -3.66210938e-02\n",
            " -7.37304688e-02 -1.77734375e-01  9.17968750e-02 -1.25000000e-01\n",
            " -1.65039062e-01 -3.57421875e-01 -2.85156250e-01 -1.66992188e-01\n",
            "  1.97265625e-01 -1.53320312e-01  2.31933594e-02  2.06054688e-01\n",
            "  1.80664062e-01 -2.74658203e-02 -1.92382812e-01 -9.61914062e-02\n",
            " -1.06811523e-02 -4.73632812e-02  6.54296875e-02 -1.25732422e-02\n",
            "  1.78222656e-02 -8.00781250e-02 -2.59765625e-01  9.37500000e-02\n",
            " -7.81250000e-02  4.68750000e-02 -2.22167969e-02  1.86767578e-02\n",
            "  3.11279297e-02  1.04980469e-02 -1.69921875e-01  2.58789062e-02\n",
            " -3.41796875e-02 -1.44042969e-02 -5.46875000e-02 -8.78906250e-02\n",
            "  1.96838379e-03  2.23632812e-01 -1.36718750e-01  1.75781250e-01\n",
            " -1.63085938e-01  1.87500000e-01  3.44238281e-02 -5.63964844e-02\n",
            " -2.27689743e-05  4.27246094e-02  5.81054688e-02 -1.07910156e-01\n",
            " -3.88183594e-02 -2.69531250e-01  3.34472656e-02  9.81445312e-02\n",
            "  5.63964844e-02  2.23632812e-01 -5.49316406e-02  1.46484375e-01\n",
            "  5.93261719e-02 -2.19726562e-01  6.39648438e-02  1.66015625e-02\n",
            "  4.56542969e-02  3.26171875e-01 -3.80859375e-01  1.70898438e-01\n",
            "  5.66406250e-02 -1.04492188e-01  1.38671875e-01 -1.57226562e-01\n",
            "  3.23486328e-03 -4.80957031e-02 -2.48046875e-01 -6.20117188e-02]\n"
          ]
        }
      ],
      "source": [
        "# word embedding\n",
        "word_vec = word2vec['computer']\n",
        "print(word_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jpz28yWHY-r",
        "outputId": "2e15d321-b26f-4377-ad15-7f80c5946ad7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 300次元であるか確認する\n",
        "word_vec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eUU_tA5Ho7Y",
        "outputId": "ff4820d5-65fb-4b93-b9b5-571ccaea91d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('computers', 0.7979379892349243),\n",
              " ('laptop', 0.6640493273735046),\n",
              " ('laptop_computer', 0.6548868417739868),\n",
              " ('Computer', 0.647333562374115),\n",
              " ('com_puter', 0.6082080006599426),\n",
              " ('technician_Leonard_Luchko', 0.5662748217582703),\n",
              " ('mainframes_minicomputers', 0.5617720484733582),\n",
              " ('laptop_computers', 0.5585449934005737),\n",
              " ('PC', 0.5539618730545044),\n",
              " ('maker_Dell_DELL.O', 0.5519254207611084)]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 類似の単語を取得する\n",
        "word2vec.most_similar('computer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxEWZPsfIfqB",
        "outputId": "129e442c-cd5b-4f1e-a20c-14d1a7f49c03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.76640123"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 類似度を計算する\n",
        "word2vec.similarity('woman', 'man')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AP1loMHIrHR",
        "outputId": "c9e498a7-2583-4267-95ca-76fedacd9000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('king', 0.7020207047462463), ('queen', 0.6933462619781494), ('princess', 0.5692708492279053), ('monarch', 0.5654875040054321), ('crown_prince', 0.5116569995880127), ('empress', 0.495297908782959), ('Queen_Consort', 0.4884769320487976), ('queens', 0.48631641268730164), ('sultan', 0.48105761408805847), ('prince', 0.47682592272758484)]\n"
          ]
        }
      ],
      "source": [
        "# king - man + woman\n",
        "result_vector = word2vec['king'] - word2vec['man'] + word2vec['woman'] - word2vec['male'] + word2vec['female']\n",
        "similar_words = word2vec.most_similar(result_vector)\n",
        "print(similar_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAvngNX8CSxA"
      },
      "source": [
        "## SpaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kjmr5mDACZbF"
      },
      "source": [
        "- pip install spacyでinstall\n",
        "- spacy.load(model_name)でモデルをロード\n",
        "  - ex: nlp = spacy.load(\"en_core_web_sm\")\n",
        "    - \"en_core_web_sm\"が小さいモデルで使いやすい. \"en_core_web_md\"(中)や\"en_core_web_lg\"(大)などリソースに応じて使い分ける\n",
        "  - https://spacy.io/\n",
        "- モデルのインスタンスに対して('word').vectorでword embeddingを取得\n",
        "- nlp('word').similarity(nlp('word2'))で2つの単語の類似度を計算\n",
        "- gensimのように類似度が高い単語を検索する機能はない"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Myo8XNvBCZKm"
      },
      "outputs": [],
      "source": [
        "# colabでは不要\n",
        "# !pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBbFdNYVGf_I"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1-I0vmlI3oC"
      },
      "outputs": [],
      "source": [
        "# モデルロード\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUfs6cI2GZ1t",
        "outputId": "d9e8ff66-4bea-4308-8eb4-d13e5f4d2569"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1.6373895 , -0.6080451 , -0.6566559 , -0.10872576, -0.24852699,\n",
              "        0.17527935,  0.7263826 ,  1.658519  , -0.1795105 , -0.57576895,\n",
              "        0.2937798 , -1.0000906 , -0.29037115, -0.21647847, -0.03370228,\n",
              "        0.7057948 , -0.7825656 , -1.2829045 ,  1.3557242 ,  0.8119894 ,\n",
              "        0.6912364 ,  0.57129043, -0.33364248, -1.0607941 ,  0.8841657 ,\n",
              "        0.25746697, -0.03119813,  0.7934418 ,  0.11529171,  0.27637503,\n",
              "       -0.3697168 ,  0.8258281 ,  1.3755571 ,  0.55934906, -0.52683127,\n",
              "       -1.1254272 ,  0.20773923,  0.47141504,  0.38074216, -0.7482727 ,\n",
              "       -0.07192928, -0.063835  , -0.5294903 ,  1.2106018 , -0.67606175,\n",
              "       -0.47462302, -0.9633928 ,  1.2195504 ,  0.205295  , -0.22966453,\n",
              "        0.32949054,  1.4156418 ,  1.0020167 , -1.0212331 ,  0.24324086,\n",
              "        0.15824679,  0.63781977, -0.5370287 ,  0.11409536, -0.44219247,\n",
              "       -0.9631854 , -0.11269182,  0.22333866, -0.07143135,  1.0847998 ,\n",
              "        0.8003227 , -0.18230852, -0.67244947,  0.09219736, -0.5087909 ,\n",
              "        0.4841568 ,  1.1335273 ,  1.3780379 , -0.4093325 ,  0.00951386,\n",
              "       -0.3827051 , -0.5394529 , -0.00996476,  0.17741328, -1.2335469 ,\n",
              "        0.32314333, -0.4584407 , -2.109942  , -1.1390811 , -0.5345154 ,\n",
              "        1.0022924 , -0.26251134, -0.5644884 , -1.4048696 ,  0.50332975,\n",
              "       -1.3758938 ,  0.22028446,  1.1431644 ,  0.62964964,  0.9079737 ,\n",
              "        0.6585612 ], dtype=float32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# word embedding\n",
        "nlp('computer').vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGoMUaDgGsAe",
        "outputId": "719a28b5-8d46-4991-ec95-73894be8017c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-15-e41c63190dc3>:2: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  nlp('woman').similarity(nlp('man'))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.9191394603322555"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 類似度を取得\n",
        "nlp('woman').similarity(nlp('man'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1PkntiMGv1q",
        "outputId": "c31605b2-a598-4275-bb46-8cce6d596c9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(96,)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 96次元のvector\n",
        "nlp('computer').vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WQsCQvbHWQ8"
      },
      "source": [
        "## fastText(with Gensim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Re_F3zHdMy"
      },
      "source": [
        "- facebookが作った自然言語処理のライブラリ\n",
        "- word2vecやGloVeとは異なるアルゴリズムを使用\n",
        "  - word2vecの拡張系\n",
        "  - 従来のword2vecよりも格段に速いことが有名\n",
        "- 単語をsubword(\"cat\"->\"ca\"/\"at\")(n_gram)に分割して扱うことで、単語の活用系(複数形や次元など)に対応\n",
        "  - CBOWやskip-gramの形でsubwordsを学習する\n",
        "- Gensimにインターフェースがあり、Gensimを介してfastTextを使用することが有名"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGcanNwtIdpT"
      },
      "source": [
        "fastText(gensimを使用)\n",
        "\n",
        "- gensim.downloaderを使用して用意されているデータセットを使用する\n",
        "  - text8: 100MBのwikipediaの英語データ\n",
        "- gensimのインターフェースを使用する\n",
        "  - gensim.models.FastTextクラスを使用してモデルを学習する\n",
        "    - sentences: tokenのリスト\n",
        "    - vector_size: embedding後のベクトルの次元\n",
        "    - window: cotextのwindowサイズ\n",
        "    - min_count: 学習の対象とする単語の最小頻度\n",
        "      - Wikipedia上で1語しか出てこないようなレアな単語を省きたい時に使用する\n",
        "    - workers: 学習時に使用するCPUのコア数\n",
        "- モデルインスタンスに対して.wv['word']でword_embeddingを取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pE2fmxUJHMhi"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHb3081jM7QT",
        "outputId": "427d3ed2-c39c-4a9e-abf7-64644b2f7542"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'num_records': 1701,\n",
              " 'record_format': 'list of str (tokens)',\n",
              " 'file_size': 33182058,\n",
              " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py',\n",
              " 'license': 'not found',\n",
              " 'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.',\n",
              " 'checksum': '68799af40b6bda07dfa47a32612e5364',\n",
              " 'file_name': 'text8.gz',\n",
              " 'read_more': ['http://mattmahoney.net/dc/textdata.html'],\n",
              " 'parts': 1}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "api.info('text8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4Juy8zANCQ9"
      },
      "outputs": [],
      "source": [
        "dataset = api.load('text8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUuuPkOpNKOr",
        "outputId": "8fda4e4c-3a80-4860-a8ba-c93e382772fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['anarchism',\n",
              " 'originated',\n",
              " 'as',\n",
              " 'a',\n",
              " 'term',\n",
              " 'of',\n",
              " 'abuse',\n",
              " 'first',\n",
              " 'used',\n",
              " 'against']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# datasetはiterの形になっている\n",
        "next(iter(dataset))[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1t7w6TNNXBA"
      },
      "outputs": [],
      "source": [
        "# 学習(5分ぐらいかかる)\n",
        "import time\n",
        "from gensim.models import FastText\n",
        "\n",
        "start_time = time.time()\n",
        "model = FastText(dataset, vector_size=100, window=5, min_count=5, workers=4)\n",
        "end_time = time.time()\n",
        "print(f'学習にかかった時間: {end_time - start_time}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-DbPzC9NknY"
      },
      "outputs": [],
      "source": [
        "# word embedding\n",
        "model.wv['computer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmvDGrHHQb-j"
      },
      "outputs": [],
      "source": [
        "# 類似度\n",
        "similarity = model.wv.similarity('woman', 'man')\n",
        "print(similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpJ78nRVR3Jq"
      },
      "outputs": [],
      "source": [
        "similarity = model.wv.similarity('computer', 'technology')\n",
        "print(similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktYZduXTR8Ka"
      },
      "outputs": [],
      "source": [
        "similarity = model.wv.similarity('king', 'technology')\n",
        "print(similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0ys7h43R_Oi"
      },
      "outputs": [],
      "source": [
        "similarity = model.wv.similarity('king', 'man')\n",
        "print(similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qRw6V62SBTo"
      },
      "outputs": [],
      "source": [
        "similarity = model.wv.similarity('king', 'queen')\n",
        "print(similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rhusbG3SJxp"
      },
      "outputs": [],
      "source": [
        "similarity = model.wv.similarity('woman', 'queen')\n",
        "print(similarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCgtyOlCYzRz"
      },
      "source": [
        "## Embadding Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1agkptOxX_yf"
      },
      "source": [
        "nn.Embedding\n",
        "\n",
        "- nn.EmbeddingでEmbedding層を作ることができる\n",
        "- .from_pretrainedで重みの初期値を指定する\n",
        "  - freeze=Trueを指定すると重みが更新されないため、既存のword embeddingを使用する形になる\n",
        "\n",
        "- gensimのword2vecからembedding matrixを作成する\n",
        "- Embedding Layerはシンプルに各単語のindexに対するword membeddingベクトルを取得しているだけ(lookupの操作)であることを確認する\n",
        "- 入力tensorには、one-hot vectorではなく、indexを使用する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_VfG5bASNZp",
        "outputId": "fcb496d4-2123-437e-a85d-65bd7b5a2d2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.KeyedVectors at 0x7c188d75f160>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 下記のword2vecのインスタンスを使う\n",
        "word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izfXoNMiajFt",
        "outputId": "119e80e4-3825-446d-fcc4-8c17ee9c2c4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3000000\n",
            "(300,)\n"
          ]
        }
      ],
      "source": [
        "# 約300万語の単語を持っている\n",
        "print(len(word2vec))\n",
        "\n",
        "# 次元は300次元\n",
        "print(word2vec['computer'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_t-XYUdaQSG",
        "outputId": "a86dd3b2-24fd-4470-8ef2-49b71237014a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-03c36e44a3e7>:8: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  embedding_matrix[i] = torch.from_numpy(word2vec[word])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# embedding matrix\n",
        "vocab_size = len(word2vec) # 実際には手元のデータのvocab sizeを指定\n",
        "embedding_dim = 300\n",
        "\n",
        "embedding_matrix = torch.zeros((vocab_size, embedding_dim))\n",
        "for i, word in enumerate(word2vec.key_to_index.keys()):\n",
        "    embedding_matrix[i] = torch.from_numpy(word2vec[word])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONH0MfR3f-qD"
      },
      "outputs": [],
      "source": [
        "# embedding layerの挙動を確認する\n",
        "import torch.nn as nn\n",
        "\n",
        "# 重みの初期値指定\n",
        "embedding_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgkR6pmQf-jj",
        "outputId": "27611a91-6f5d-41a6-8dea-3f0145d912ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.0703,  0.0869,  0.0879,  ..., -0.0476,  0.0145, -0.0625],\n",
              "         [-0.0118, -0.0474,  0.0447,  ...,  0.0713, -0.0349,  0.0242],\n",
              "         [-0.0157, -0.0283,  0.0835,  ...,  0.0069,  0.0610, -0.1484]],\n",
              "\n",
              "        [[ 0.0070, -0.0732,  0.1719,  ...,  0.0112,  0.1641,  0.1069],\n",
              "         [ 0.0267, -0.0908,  0.0278,  ..., -0.1167, -0.0294, -0.0708],\n",
              "         [ 0.1689, -0.0630, -0.0003,  ...,  0.0238, -0.1235,  0.0164]]])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# forward処理のテスト\n",
        "text = torch.tensor([[1, 2, 3], [4, 5, 6]])  # textは3つの単語の2つの文章\n",
        "out = embedding_layer(text)\n",
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5TqG3Qpf-cf"
      },
      "outputs": [],
      "source": [
        "# 単語とその埋め込みベクトルの確認\n",
        "i, j = 0, 0\n",
        "word = list(word2vec.key_to_index.keys())[text[i, j]]\n",
        "print(f'index:{i} is word: \"{word}\"')\n",
        "# print(embedding_matrix[text[i, j]])\n",
        "\n",
        "# embedding_layerとembedding_matrixが等しいことをテスト\n",
        "assert torch.all(embedding_layer(text[i, j]) == embedding_matrix[text[i, j]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REUNBFKxf-Sw",
        "outputId": "8c0e06f4-822d-4fe0-b535-0484eecca27d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.0703, 0.0869, 0.0879, 0.0625, 0.0693])\n",
            "tensor([0.0703, 0.0869, 0.0879, 0.0625, 0.0693])\n"
          ]
        }
      ],
      "source": [
        "# embedding_layerとembedding_matrixが等しいことをテスト\n",
        "print(embedding_layer(text[i, j])[:5])\n",
        "print(embedding_matrix[text[i, j]][:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuPIU7PPo35D"
      },
      "outputs": [],
      "source": [
        "# 重みから直接indexした結果\n",
        "assert torch.all(embedding_layer.weight[text, :] == out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fecm1HjpdNbt",
        "outputId": "44ee41f1-f4e8-44ca-f650-265c1796b754"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([300])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# index:0(0個目)の単語のベクトル\n",
        "embedding_matrix[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsrxiirSbSMC",
        "outputId": "49a0eca8-3855-411f-deb3-f20d56986ab8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3000000, 300])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 300次元の単語が3000000個ある\n",
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ZM_C4nVOgcjj",
        "outputId": "343063f1-ccaa-4bd8-a1a6-4f89596208c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ]
        }
      ],
      "source": [
        "word2vec.key_to_index.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LiUcUYB74XZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}