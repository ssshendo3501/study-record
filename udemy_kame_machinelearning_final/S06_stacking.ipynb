{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23fd4d69-aec4-4f7e-b804-a9b5facd1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c908e5-09cb-4a01-a1c1-74dc3b8abff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_393/1260895635.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[cat_cols] = oe.fit_transform(X[cat_cols])\n"
     ]
    }
   ],
   "source": [
    "# データ準備\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 欠損値削除\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# X,y生成\n",
    "X = df.loc[:, (df.columns!='survived') & (df.columns!='alive')]\n",
    "y = df['survived']\n",
    "\n",
    "# ラベルエンコーディング\n",
    "# .set_output(transform='pandas')：　oeがnumpyで返るのをpandasにする\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder()\n",
    "cat_cols = X.select_dtypes(exclude=np.number).columns.to_list()\n",
    "oe.set_output(transform='pandas')\n",
    "X[cat_cols] = oe.fit_transform(X[cat_cols])\n",
    "\n",
    "# 学習/テストデータ分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5267ab-9e61-45b6-a43f-8294b67904f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "232b20cb-8cd8-474b-b7e9-b21a3a0b429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   3   4   5   6   9  11  12  13  14  15  17  18  19  20  21  23\n",
      "  25  26  27  28  29  31  32  33  34  35  36  37  38  39  41  42  43  44\n",
      "  45  46  47  49  50  52  53  54  55  56  57  58  60  61  62  63  64  65\n",
      "  67  68  69  70  72  74  75  76  77  79  80  81  82  83  84  86  87  88\n",
      "  90  93  94  96  97  99 102 103 104 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120 121 122 123 124 125] [  2   7   8  10  16  22  24  30  40  48  51  59  66  71  73  78  85  89\n",
      "  91  92  95  98 100 101 105 126]\n",
      "[  0   1   2   4   5   7   8   9  10  12  14  15  16  17  19  20  21  22\n",
      "  23  24  25  28  29  30  31  32  34  35  36  37  38  39  40  41  42  44\n",
      "  46  47  48  49  51  53  55  56  57  58  59  61  64  65  66  67  69  70\n",
      "  71  72  73  74  76  77  78  79  80  81  82  83  85  86  87  88  89  90\n",
      "  91  92  93  95  97  98  99 100 101 102 103 105 106 108 109 111 112 113\n",
      " 114 115 116 117 118 119 120 122 123 125 126] [  3   6  11  13  18  26  27  33  43  45  50  52  54  60  62  63  68  75\n",
      "  84  94  96 104 107 110 121 124]\n",
      "[  2   3   6   7   8   9  10  11  12  13  14  16  18  19  20  21  22  24\n",
      "  25  26  27  29  30  31  32  33  36  37  39  40  43  44  45  46  47  48\n",
      "  49  50  51  52  54  57  58  59  60  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  75  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  94  95  96  97  98 100 101 102 103 104 105 106 107 108 110 111\n",
      " 112 114 116 117 119 120 121 122 123 124 125 126] [  0   1   4   5  15  17  23  28  34  35  38  41  42  53  55  56  61  74\n",
      "  76  93  99 109 113 115 118]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18\n",
      "  21  22  23  24  26  27  28  30  33  34  35  36  38  39  40  41  42  43\n",
      "  44  45  46  47  48  50  51  52  53  54  55  56  58  59  60  61  62  63\n",
      "  64  65  66  67  68  70  71  73  74  75  76  78  81  83  84  85  87  88\n",
      "  89  91  92  93  94  95  96  98  99 100 101 102 103 104 105 107 109 110\n",
      " 111 112 113 114 115 116 117 118 121 122 124 126] [ 14  19  20  25  29  31  32  37  49  57  69  72  77  79  80  82  86  90\n",
      "  97 106 108 119 120 123 125]\n",
      "[  0   1   2   3   4   5   6   7   8  10  11  13  14  15  16  17  18  19\n",
      "  20  22  23  24  25  26  27  28  29  30  31  32  33  34  35  37  38  40\n",
      "  41  42  43  45  48  49  50  51  52  53  54  55  56  57  59  60  61  62\n",
      "  63  66  68  69  71  72  73  74  75  76  77  78  79  80  82  84  85  86\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 104 105 106 107 108\n",
      " 109 110 113 115 118 119 120 121 123 124 125 126] [  9  12  21  36  39  44  46  47  58  64  65  67  70  81  83  87  88 102\n",
      " 103 111 112 114 116 117 122]\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in cv.split(X_train):\n",
    "    print(train_idx, test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2178fd-72ac-4347-808f-cec97a5b998b",
   "metadata": {},
   "source": [
    "# Section6 stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ccf8e6-a0d6-4199-91fe-96af3d9f160a",
   "metadata": {},
   "source": [
    "- StackingClasifierCVクラス\n",
    "    - sklearn.ensemble.StackingClassifierクラスは1層目のモデルの学習の時にCrossValidationを使っていない\n",
    "    - そのため、CrossValidationに対応するクラスを新しくスクラッチで作る\n",
    "    - 設計要件\n",
    "        - 2値分類のみ対応\n",
    "        - estimator引数: 1層目のモデルのリスト(['model_name', model), ...]\n",
    "        - final_estimator引数: 2層目のsklearnのモデルインスタンス\n",
    "        - cv引数: sklearnのcvオブジェクト\n",
    "        - .fit()および、.predict_probaメソッドを実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b086d9c4-5e4b-4e73-94bc-d4257926b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingClassifierCV():\n",
    "    \n",
    "    def __init__(self, estimators, final_estimator, cv):\n",
    "        self.estimators = estimators # [('rf', RandomForestClassifier()), ('knn', KNeighborsCalssifier()), (,), ..]\n",
    "        self.final_estimator = final_estimator\n",
    "        self.cv = cv\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        pred_features = {}\n",
    "        # 1層目のモデル学習\n",
    "        for model_name, model in self.estimators:\n",
    "            preds = []\n",
    "            new_y = []\n",
    "            \n",
    "            for train_idx, val_idx in self.cv.split(X):\n",
    "                X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "                y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                model.fit(X_train, y_train)\n",
    "                pred = model.predict_proba(X_val)[:, 1].tolist()\n",
    "                preds += pred\n",
    "                # cv.splitによりXの順番が変わっているので，それに合わせて新しくyを作成する\n",
    "                new_y += y_val.tolist()\n",
    "            model.fit(X, y)\n",
    "            pred_features[model_name] = preds\n",
    "        \n",
    "        # 2層目のモデル学習\n",
    "        new_X = pd.DataFrame(pred_features)\n",
    "        self.final_estimator.fit(new_X, new_y)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # 1層目のモデルで特徴量(予測値)生成\n",
    "        pred_features = {}\n",
    "        for model_name, model in self.estimators:\n",
    "            pred = model.predict_proba(X)[:, 1]\n",
    "            pred_features[model_name] = pred\n",
    "        \n",
    "        new_X = pd.DataFrame(pred_features)\n",
    "        final_pred = self.final_estimator.predict_proba(new_X)\n",
    "        return final_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9860ac2d-c9d6-4f12-a83f-4c3e65b0353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44515855, 0.55484145],\n",
       "       [0.63171789, 0.36828211],\n",
       "       [0.30593782, 0.69406218],\n",
       "       [0.20691563, 0.79308437],\n",
       "       [0.46214456, 0.53785544],\n",
       "       [0.51421666, 0.48578334],\n",
       "       [0.56963174, 0.43036826],\n",
       "       [0.25777583, 0.74222417],\n",
       "       [0.21484872, 0.78515128],\n",
       "       [0.17009214, 0.82990786],\n",
       "       [0.57473886, 0.42526114],\n",
       "       [0.16634065, 0.83365935],\n",
       "       [0.21889727, 0.78110273],\n",
       "       [0.17009214, 0.82990786],\n",
       "       [0.33181466, 0.66818534],\n",
       "       [0.52165375, 0.47834625],\n",
       "       [0.23031403, 0.76968597],\n",
       "       [0.21484872, 0.78515128],\n",
       "       [0.23189974, 0.76810026],\n",
       "       [0.43195548, 0.56804452],\n",
       "       [0.24050024, 0.75949976],\n",
       "       [0.37466421, 0.62533579],\n",
       "       [0.20303108, 0.79696892],\n",
       "       [0.19495845, 0.80504155],\n",
       "       [0.26121329, 0.73878671],\n",
       "       [0.49782919, 0.50217081],\n",
       "       [0.28364946, 0.71635054],\n",
       "       [0.25324134, 0.74675866],\n",
       "       [0.42538882, 0.57461118],\n",
       "       [0.40800848, 0.59199152],\n",
       "       [0.49038355, 0.50961645],\n",
       "       [0.21484872, 0.78515128],\n",
       "       [0.18397849, 0.81602151],\n",
       "       [0.29035333, 0.70964667],\n",
       "       [0.16306122, 0.83693878],\n",
       "       [0.32197926, 0.67802074],\n",
       "       [0.15353509, 0.84646491],\n",
       "       [0.23189974, 0.76810026],\n",
       "       [0.48368498, 0.51631502],\n",
       "       [0.40872714, 0.59127286],\n",
       "       [0.40872714, 0.59127286],\n",
       "       [0.26236299, 0.73763701],\n",
       "       [0.36425109, 0.63574891],\n",
       "       [0.27703161, 0.72296839],\n",
       "       [0.38026574, 0.61973426],\n",
       "       [0.20303108, 0.79696892],\n",
       "       [0.21085483, 0.78914517],\n",
       "       [0.64273849, 0.35726151],\n",
       "       [0.45105381, 0.54894619],\n",
       "       [0.51495966, 0.48504034],\n",
       "       [0.43195548, 0.56804452],\n",
       "       [0.15353509, 0.84646491],\n",
       "       [0.47401448, 0.52598552],\n",
       "       [0.23189974, 0.76810026],\n",
       "       [0.21889727, 0.78110273]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "final_estimator = LogisticRegression()\n",
    "my_stacking = StackingClassifierCV(estimators=[('rf', RandomForestClassifier()), ('knn', KNeighborsClassifier(n_neighbors=5))], \n",
    "                                   final_estimator=final_estimator, \n",
    "                                   cv=cv)\n",
    "\n",
    "my_stacking.fit(X_train, y_train)\n",
    "my_stacking.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f57df0e5-3f5a-4144-949f-26d34e809957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 一層目のモデル\n",
    "estimators=[('rf', RandomForestClassifier()), ('knn', KNeighborsClassifier()), ('logistic', LogisticRegression())]\n",
    "# 二層目のモデル\n",
    "final_estimator = LogisticRegression()\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "stacking_cv = StackingClassifierCV(estimators=estimators,\n",
    "                                   final_estimator=final_estimator,\n",
    "                                   cv=cv)\n",
    "stacking_cv.fit(X_train, y_train)\n",
    "y_pred_stacking_cv = stacking_cv.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0940388-f0f6-45d9-8a33-aa2cfedaad0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
