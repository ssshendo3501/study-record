{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d9bafa-c8a2-4549-9a45-d16cb0644c6b",
   "metadata": {},
   "source": [
    "# SaveとLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f450867d-d593-4a60-84e6-817f325a5db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import optim, nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fbb59c-7406-42a3-8a68-daec5b37bc67",
   "metadata": {},
   "source": [
    "## Early Stoping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d3d1c-dd44-426c-a8f0-2a6619e12c8f",
   "metadata": {},
   "source": [
    "- 以前作成した学習ループを関数化し、early stoppingを追加する\n",
    "    - early stopping引数を追加し、early stopping数のepoch数検証データの損失が現象しなかったら学習を止めるようにする\n",
    "    - early_stopping引数にNoneを指定すると、early_stoppingしないようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3b23edb-3d23-4d92-8c57-cd2213253cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================MLP自作クラス=================\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_in, num_hidden, num_out):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten() # [b, c, h, w] -> [b, cxhxw]\n",
    "        self.l1 = nn.Linear(num_in, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, num_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # z1 = self.l1(x)\n",
    "        # a1 = F.relu(z1)\n",
    "        # z2 = self.l2(a1)\n",
    "        x = self.l2(F.relu(self.l1(self.flatten(x))))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "559269cb-6274-442a-8ddb-6ec0cde2b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============自作Datasetクラス=============\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8a4cfe-cf93-4e8a-a209-b04e5f105e1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============自作学習ループ関数=============\n",
    "def learn(model, train_loader, val_loader, opt, loss_func, num_epoch, early_stopping=None):\n",
    "    # ログ\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_loss = float('inf')  # 1回目のval_lossを無限大とする\n",
    "    no_improve = 0 # early stoppingのカウント用変数\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        running_loss = 0.0\n",
    "        running_val_loss = 0.0\n",
    "        running_val_accuracy = 0.0\n",
    "        \n",
    "        for train_batch, data in enumerate(train_loader):\n",
    "            \n",
    "            X, y = data\n",
    "            \n",
    "            # mini batch作成 -> 削除\n",
    "    \n",
    "            # 順伝播と逆伝播の計算\n",
    "            opt.zero_grad()\n",
    "            # forward\n",
    "            preds = model.forward(X) \n",
    "            loss = loss_func(preds, y)\n",
    "            running_loss += loss.item()\n",
    "            # backward\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            for val_batch, data in enumerate(val_loader):\n",
    "                X_val, y_val = data\n",
    "                \n",
    "                preds_val = model(X_val)  \n",
    "                val_loss = loss_func(preds_val, y_val)\n",
    "                running_val_loss += val_loss.item()\n",
    "                val_accuracy = torch.sum(torch.argmax(preds_val, dim=-1) == y_val) / y_val.shape[0] \n",
    "                running_val_accuracy += val_accuracy.item()\n",
    "    \n",
    "        train_losses.append(running_loss/(train_batch + 1))\n",
    "        val_losses.append(running_val_loss/(val_batch + 1))\n",
    "        val_accuracies.append(running_val_accuracy/(val_batch + 1))\n",
    "        print(f'epoch: {epoch}: train error: {train_losses[-1]}, validation error: {val_losses[-1]}, validation accuracy: {val_accuracies[-1]}')\n",
    "    \n",
    "        # early ｓｔｏｐｐｉｎｇ\n",
    "        if val_losses[-1] < best_val_loss:\n",
    "            best_val_loss = val_losses[-1]\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "    \n",
    "        if early_stopping and no_improve >= early_stopping:\n",
    "            print('Stoping early')\n",
    "            break\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84a8c3f-71e3-45cd-8b31-b3b7f84e227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データロード\n",
    "dataset = datasets.load_digits()\n",
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "images = dataset['images']\n",
    "images = images * (255.0 / 16.0)  # 0-16 -> 0-255\n",
    "images = images.astype(np.uint8)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cdbbff7-9c34-4560-a251-26b7157bfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 0-255 -> 0-1\n",
    "    transforms.Normalize((0.5, ), (0.5, ))  # 0-1 -> -1-1\n",
    "])\n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train, transform)\n",
    "val_dataset = MyDataset(X_val, y_val, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbf709ac-bc6b-4ac4-bc62-dd934ed54530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "bacth_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=bacth_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=bacth_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20effedb-0699-4832-9207-3bfe83d4b176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0: train error: 1.9253755410512288, validation error: 1.4110961655775707, validation accuracy: 0.734375\n",
      "epoch: 1: train error: 0.9216277817885081, validation error: 0.6085369239250819, validation accuracy: 0.8671875\n",
      "epoch: 2: train error: 0.4507127304871877, validation error: 0.35984476655721664, validation accuracy: 0.9270833333333334\n",
      "epoch: 3: train error: 0.2993488291899363, validation error: 0.2749025896191597, validation accuracy: 0.9296875\n",
      "epoch: 4: train error: 0.24014668845468098, validation error: 0.23042329649130502, validation accuracy: 0.9375\n",
      "epoch: 5: train error: 0.1973070114850998, validation error: 0.19665620227654776, validation accuracy: 0.9427083333333334\n",
      "epoch: 6: train error: 0.17027435277899106, validation error: 0.1773274807880322, validation accuracy: 0.953125\n",
      "epoch: 7: train error: 0.1525686118337843, validation error: 0.161989391160508, validation accuracy: 0.953125\n",
      "epoch: 8: train error: 0.1384750989576181, validation error: 0.1509710323686401, validation accuracy: 0.9505208333333334\n",
      "epoch: 9: train error: 0.1287962002058824, validation error: 0.14517009630799294, validation accuracy: 0.9557291666666666\n",
      "epoch: 10: train error: 0.11624858073062366, validation error: 0.13618819353481135, validation accuracy: 0.9583333333333334\n",
      "epoch: 11: train error: 0.11234469181961483, validation error: 0.1300885295495391, validation accuracy: 0.9557291666666666\n",
      "epoch: 12: train error: 0.10418530996474955, validation error: 0.12356948542098205, validation accuracy: 0.9583333333333334\n",
      "epoch: 13: train error: 0.09954687597023117, validation error: 0.1329831158121427, validation accuracy: 0.9635416666666666\n",
      "epoch: 14: train error: 0.09094718471169472, validation error: 0.12150777115797003, validation accuracy: 0.9635416666666666\n",
      "epoch: 15: train error: 0.0846190347439713, validation error: 0.12148574382687609, validation accuracy: 0.9609375\n",
      "epoch: 16: train error: 0.08113778130047851, validation error: 0.10976366652175784, validation accuracy: 0.9635416666666666\n",
      "epoch: 17: train error: 0.07776875466936164, validation error: 0.11087438914303978, validation accuracy: 0.9635416666666666\n",
      "epoch: 18: train error: 0.07212947010993957, validation error: 0.10654922729978959, validation accuracy: 0.9609375\n",
      "epoch: 19: train error: 0.06890349404679405, validation error: 0.10633206289882462, validation accuracy: 0.96875\n",
      "epoch: 20: train error: 0.06337460598184003, validation error: 0.11090134254967172, validation accuracy: 0.9713541666666666\n",
      "epoch: 21: train error: 0.05972730869220363, validation error: 0.10798359413941701, validation accuracy: 0.9739583333333334\n",
      "epoch: 22: train error: 0.06067224397427506, validation error: 0.10240623727440834, validation accuracy: 0.96875\n",
      "epoch: 23: train error: 0.055913665890693666, validation error: 0.10579343140125275, validation accuracy: 0.9739583333333334\n",
      "epoch: 24: train error: 0.054395550427337486, validation error: 0.10252798271055023, validation accuracy: 0.96875\n",
      "epoch: 25: train error: 0.05144176839126481, validation error: 0.10040840165068705, validation accuracy: 0.9739583333333334\n",
      "epoch: 26: train error: 0.05034790506793393, validation error: 0.09568469955896337, validation accuracy: 0.9713541666666666\n",
      "epoch: 27: train error: 0.04705100624511639, validation error: 0.10113456558125715, validation accuracy: 0.96875\n",
      "epoch: 28: train error: 0.04613681694285737, validation error: 0.10083151864819229, validation accuracy: 0.9713541666666666\n",
      "epoch: 29: train error: 0.0448210375280016, validation error: 0.0944791881678005, validation accuracy: 0.9765625\n",
      "epoch: 30: train error: 0.04134344015684393, validation error: 0.09716520799944799, validation accuracy: 0.9713541666666666\n",
      "epoch: 31: train error: 0.041729738232162264, validation error: 0.09991771875259776, validation accuracy: 0.96875\n",
      "epoch: 32: train error: 0.039939659445857006, validation error: 0.09445512884606917, validation accuracy: 0.9713541666666666\n",
      "epoch: 33: train error: 0.03719834933678309, validation error: 0.09577082276033859, validation accuracy: 0.9713541666666666\n",
      "epoch: 34: train error: 0.03720710834281312, validation error: 0.0916468574044605, validation accuracy: 0.9765625\n",
      "epoch: 35: train error: 0.03405042851550712, validation error: 0.09485562269886334, validation accuracy: 0.9713541666666666\n",
      "epoch: 36: train error: 0.034079106172753705, validation error: 0.09581964835524559, validation accuracy: 0.9739583333333334\n",
      "epoch: 37: train error: 0.03168881218880415, validation error: 0.09600541011119883, validation accuracy: 0.9713541666666666\n",
      "epoch: 38: train error: 0.03122945558279753, validation error: 0.09435130779941876, validation accuracy: 0.9739583333333334\n",
      "epoch: 39: train error: 0.031225913287036947, validation error: 0.09414410792912047, validation accuracy: 0.9765625\n",
      "Stoping early\n"
     ]
    }
   ],
   "source": [
    "# Refactoring後の学習ループ\n",
    "num_in = 64\n",
    "num_hidden = 30\n",
    "num_out = 10\n",
    "model = MLP(num_in, num_hidden, num_out)\n",
    "learning_rate = 0.1\n",
    "opt = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epoch = 100\n",
    "train_losses, val_losses, val_accuracies = learn(model, train_loader, val_loader, opt, F.cross_entropy, num_epoch, early_stopping=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "210496fd-868c-4f36-9b96-aaeb5def6a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f35221536d0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8f20c7c-1c8b-477e-b166-7fb3c88b4f37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0: train error: 1.86846145523919, validation error: 1.2918465435504913, validation accuracy: 0.7604166666666666\n",
      "epoch: 1: train error: 0.8670308709144592, validation error: 0.5655098358790079, validation accuracy: 0.890625\n",
      "epoch: 2: train error: 0.437890664074156, validation error: 0.36555234094460803, validation accuracy: 0.890625\n",
      "epoch: 3: train error: 0.301716262433264, validation error: 0.27972996421158314, validation accuracy: 0.9270833333333334\n",
      "epoch: 4: train error: 0.23753240075376297, validation error: 0.2252084438999494, validation accuracy: 0.9401041666666666\n",
      "epoch: 5: train error: 0.1984920947915978, validation error: 0.19589821932216486, validation accuracy: 0.9375\n",
      "epoch: 6: train error: 0.17775078465541203, validation error: 0.18170556363960108, validation accuracy: 0.953125\n",
      "epoch: 7: train error: 0.15561074250274234, validation error: 0.1651856228709221, validation accuracy: 0.9453125\n",
      "epoch: 8: train error: 0.14088542759418488, validation error: 0.14842553188403448, validation accuracy: 0.9583333333333334\n",
      "epoch: 9: train error: 0.12765938548578157, validation error: 0.14021647038559118, validation accuracy: 0.9609375\n",
      "epoch: 10: train error: 0.11770472493436601, validation error: 0.1332269043972095, validation accuracy: 0.9583333333333334\n",
      "epoch: 11: train error: 0.1108223574442996, validation error: 0.1413883681719502, validation accuracy: 0.9609375\n",
      "epoch: 12: train error: 0.10199616013301743, validation error: 0.13208184329171976, validation accuracy: 0.9583333333333334\n",
      "epoch: 13: train error: 0.0981691068659226, validation error: 0.12013100041076541, validation accuracy: 0.9609375\n",
      "epoch: 14: train error: 0.09337756145331595, validation error: 0.11647121980786324, validation accuracy: 0.9609375\n",
      "epoch: 15: train error: 0.08751141300631894, validation error: 0.11634501907974482, validation accuracy: 0.9635416666666666\n",
      "epoch: 16: train error: 0.08527351220448812, validation error: 0.118060030353566, validation accuracy: 0.9661458333333334\n",
      "epoch: 17: train error: 0.08064692525400055, validation error: 0.10447654966264963, validation accuracy: 0.9739583333333334\n",
      "epoch: 18: train error: 0.07559788198106819, validation error: 0.09974571053559582, validation accuracy: 0.96875\n",
      "epoch: 19: train error: 0.06921488977968693, validation error: 0.10730622134481867, validation accuracy: 0.9635416666666666\n",
      "epoch: 20: train error: 0.06806760496563381, validation error: 0.10235512613629301, validation accuracy: 0.9765625\n",
      "epoch: 21: train error: 0.06542237928758064, validation error: 0.09619979870816071, validation accuracy: 0.96875\n",
      "epoch: 22: train error: 0.06239945669141081, validation error: 0.1017786458445092, validation accuracy: 0.9661458333333334\n",
      "epoch: 23: train error: 0.06297069845928085, validation error: 0.09579201244438688, validation accuracy: 0.9713541666666666\n",
      "epoch: 24: train error: 0.059239507880475786, validation error: 0.09436343517154455, validation accuracy: 0.9713541666666666\n",
      "epoch: 25: train error: 0.055557227600365876, validation error: 0.09692161491451164, validation accuracy: 0.9713541666666666\n",
      "epoch: 26: train error: 0.05448735023124351, validation error: 0.09231884762023886, validation accuracy: 0.9739583333333334\n",
      "epoch: 27: train error: 0.051739238533708785, validation error: 0.09285516198724508, validation accuracy: 0.9739583333333334\n",
      "epoch: 28: train error: 0.050348256093760334, validation error: 0.09240484959445894, validation accuracy: 0.9713541666666666\n",
      "epoch: 29: train error: 0.04779590860837036, validation error: 0.08969123366599281, validation accuracy: 0.9713541666666666\n",
      "epoch: 30: train error: 0.046431589002410574, validation error: 0.09135167199807863, validation accuracy: 0.9739583333333334\n",
      "epoch: 31: train error: 0.04375633341777656, validation error: 0.08962979540228844, validation accuracy: 0.9765625\n",
      "epoch: 32: train error: 0.04335437549485101, validation error: 0.09217172154846291, validation accuracy: 0.9739583333333334\n",
      "epoch: 33: train error: 0.0413533840328455, validation error: 0.08865428195955853, validation accuracy: 0.9739583333333334\n",
      "epoch: 34: train error: 0.04036232121288776, validation error: 0.09084847002911071, validation accuracy: 0.9739583333333334\n",
      "epoch: 35: train error: 0.03954756963584158, validation error: 0.08696615773563583, validation accuracy: 0.9739583333333334\n",
      "epoch: 36: train error: 0.03782269079238176, validation error: 0.09913912337894241, validation accuracy: 0.9661458333333334\n",
      "epoch: 37: train error: 0.037442554854270484, validation error: 0.0877062954629461, validation accuracy: 0.9739583333333334\n",
      "epoch: 38: train error: 0.03541679496152533, validation error: 0.09024397493340075, validation accuracy: 0.9739583333333334\n",
      "epoch: 39: train error: 0.03422635021722979, validation error: 0.08896678080782294, validation accuracy: 0.9713541666666666\n",
      "epoch: 40: train error: 0.03186399551729361, validation error: 0.0928453862046202, validation accuracy: 0.9713541666666666\n",
      "epoch: 41: train error: 0.03153090291760034, validation error: 0.09234435976638149, validation accuracy: 0.9739583333333334\n",
      "epoch: 42: train error: 0.03102111884703239, validation error: 0.08869936418098708, validation accuracy: 0.9739583333333334\n",
      "epoch: 43: train error: 0.029809166428943476, validation error: 0.08898206482020517, validation accuracy: 0.9739583333333334\n",
      "epoch: 44: train error: 0.02905234541847474, validation error: 0.08808236957217257, validation accuracy: 0.9713541666666666\n",
      "epoch: 45: train error: 0.02728340963108672, validation error: 0.08948289121811588, validation accuracy: 0.9713541666666666\n",
      "epoch: 46: train error: 0.027637300205727418, validation error: 0.08843539267157514, validation accuracy: 0.9739583333333334\n",
      "epoch: 47: train error: 0.027554908881170882, validation error: 0.08809833802903692, validation accuracy: 0.9791666666666666\n",
      "epoch: 48: train error: 0.026532549473146597, validation error: 0.0870251648593694, validation accuracy: 0.9739583333333334\n",
      "epoch: 49: train error: 0.025309749713374508, validation error: 0.0903803971208011, validation accuracy: 0.9739583333333334\n",
      "epoch: 50: train error: 0.024759572558104993, validation error: 0.09361115555899839, validation accuracy: 0.9713541666666666\n",
      "epoch: 51: train error: 0.02479303940716717, validation error: 0.08937365965296824, validation accuracy: 0.9713541666666666\n",
      "epoch: 52: train error: 0.024541440797555776, validation error: 0.09058863716199994, validation accuracy: 0.9765625\n",
      "epoch: 53: train error: 0.023465162510466243, validation error: 0.09140166915797938, validation accuracy: 0.9739583333333334\n",
      "epoch: 54: train error: 0.021704002718130746, validation error: 0.09390862693544477, validation accuracy: 0.9739583333333334\n",
      "epoch: 55: train error: 0.02166307804485162, validation error: 0.08913027673649292, validation accuracy: 0.9739583333333334\n",
      "epoch: 56: train error: 0.021954151491324108, validation error: 0.08927973278332502, validation accuracy: 0.9739583333333334\n",
      "epoch: 57: train error: 0.021642173961218862, validation error: 0.08919051052847256, validation accuracy: 0.9739583333333334\n",
      "epoch: 58: train error: 0.020619114752237995, validation error: 0.08963028395858903, validation accuracy: 0.9739583333333334\n",
      "epoch: 59: train error: 0.019732913007545802, validation error: 0.08900793191666405, validation accuracy: 0.9739583333333334\n",
      "epoch: 60: train error: 0.019734069725705516, validation error: 0.09094169417706628, validation accuracy: 0.9739583333333334\n",
      "epoch: 61: train error: 0.02023508144646055, validation error: 0.08926856541074812, validation accuracy: 0.9739583333333334\n",
      "epoch: 62: train error: 0.019031532543400922, validation error: 0.08860800326025735, validation accuracy: 0.9739583333333334\n",
      "epoch: 63: train error: 0.01824976564902398, validation error: 0.08919783844612539, validation accuracy: 0.9739583333333334\n",
      "epoch: 64: train error: 0.018096455838531256, validation error: 0.0889099429283912, validation accuracy: 0.9739583333333334\n",
      "epoch: 65: train error: 0.017036394868046045, validation error: 0.09149915593055387, validation accuracy: 0.9739583333333334\n",
      "epoch: 66: train error: 0.01764921309529907, validation error: 0.09239753479293238, validation accuracy: 0.9739583333333334\n",
      "epoch: 67: train error: 0.01668515598349687, validation error: 0.09007848465504746, validation accuracy: 0.9713541666666666\n",
      "epoch: 68: train error: 0.015905161905619834, validation error: 0.08885344944428653, validation accuracy: 0.9739583333333334\n",
      "epoch: 69: train error: 0.016144806343234248, validation error: 0.09018041224529345, validation accuracy: 0.9713541666666666\n",
      "epoch: 70: train error: 0.016555106846822633, validation error: 0.09188322136954714, validation accuracy: 0.9739583333333334\n",
      "epoch: 71: train error: 0.015468389755632314, validation error: 0.08880613200987379, validation accuracy: 0.9765625\n",
      "epoch: 72: train error: 0.015167834066475431, validation error: 0.0909685647347942, validation accuracy: 0.9739583333333334\n",
      "epoch: 73: train error: 0.01469805262879365, validation error: 0.08957101800478995, validation accuracy: 0.9765625\n",
      "epoch: 74: train error: 0.014674714957881306, validation error: 0.09037877630908042, validation accuracy: 0.9739583333333334\n",
      "epoch: 75: train error: 0.014026585394620067, validation error: 0.09346122077355783, validation accuracy: 0.9765625\n",
      "epoch: 76: train error: 0.013936515975122651, validation error: 0.09056744759436697, validation accuracy: 0.9739583333333334\n",
      "epoch: 77: train error: 0.01362536781364017, validation error: 0.09107063186820596, validation accuracy: 0.9739583333333334\n",
      "epoch: 78: train error: 0.013487351473627819, validation error: 0.09022505069151521, validation accuracy: 0.9739583333333334\n",
      "epoch: 79: train error: 0.012876412818311818, validation error: 0.09360825996069859, validation accuracy: 0.9739583333333334\n",
      "epoch: 80: train error: 0.013042219679078294, validation error: 0.090798417183881, validation accuracy: 0.9713541666666666\n",
      "epoch: 81: train error: 0.012712313643553191, validation error: 0.09115648735314608, validation accuracy: 0.9739583333333334\n",
      "epoch: 82: train error: 0.012464956204510397, validation error: 0.09310970618389547, validation accuracy: 0.9739583333333334\n",
      "epoch: 83: train error: 0.011860070030929313, validation error: 0.09436457340295117, validation accuracy: 0.9739583333333334\n",
      "epoch: 84: train error: 0.012189893499534163, validation error: 0.09098407866743703, validation accuracy: 0.9739583333333334\n",
      "epoch: 85: train error: 0.011718336409992642, validation error: 0.09305977829111119, validation accuracy: 0.9739583333333334\n",
      "epoch: 86: train error: 0.011378153801585238, validation error: 0.09331318592497458, validation accuracy: 0.9739583333333334\n",
      "epoch: 87: train error: 0.011656971389634741, validation error: 0.09132242761552334, validation accuracy: 0.9713541666666666\n",
      "epoch: 88: train error: 0.011266294815060165, validation error: 0.09255148482043296, validation accuracy: 0.9739583333333334\n",
      "epoch: 89: train error: 0.011567544960416853, validation error: 0.09409354574745521, validation accuracy: 0.9713541666666666\n",
      "epoch: 90: train error: 0.010754821765133076, validation error: 0.09212345090539505, validation accuracy: 0.9739583333333334\n",
      "epoch: 91: train error: 0.010662803873937162, validation error: 0.09390293585602194, validation accuracy: 0.9739583333333334\n",
      "epoch: 92: train error: 0.010723148643349608, validation error: 0.09432312081723164, validation accuracy: 0.9713541666666666\n",
      "epoch: 93: train error: 0.01038057710458007, validation error: 0.09322711344187458, validation accuracy: 0.9713541666666666\n",
      "epoch: 94: train error: 0.010024556794410779, validation error: 0.09439794005205233, validation accuracy: 0.9739583333333334\n",
      "epoch: 95: train error: 0.00996523986880978, validation error: 0.0922819960784788, validation accuracy: 0.9713541666666666\n",
      "epoch: 96: train error: 0.010144771182806128, validation error: 0.0938133819339176, validation accuracy: 0.9739583333333334\n",
      "epoch: 97: train error: 0.00977470215358254, validation error: 0.09392942404762532, validation accuracy: 0.9713541666666666\n",
      "epoch: 98: train error: 0.009534295462071896, validation error: 0.0946479463018477, validation accuracy: 0.9739583333333334\n",
      "epoch: 99: train error: 0.0094191923401215, validation error: 0.09365276930232842, validation accuracy: 0.9739583333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.86846145523919,\n",
       "  0.8670308709144592,\n",
       "  0.437890664074156,\n",
       "  0.301716262433264,\n",
       "  0.23753240075376297,\n",
       "  0.1984920947915978,\n",
       "  0.17775078465541203,\n",
       "  0.15561074250274234,\n",
       "  0.14088542759418488,\n",
       "  0.12765938548578157,\n",
       "  0.11770472493436601,\n",
       "  0.1108223574442996,\n",
       "  0.10199616013301743,\n",
       "  0.0981691068659226,\n",
       "  0.09337756145331595,\n",
       "  0.08751141300631894,\n",
       "  0.08527351220448812,\n",
       "  0.08064692525400055,\n",
       "  0.07559788198106819,\n",
       "  0.06921488977968693,\n",
       "  0.06806760496563381,\n",
       "  0.06542237928758064,\n",
       "  0.06239945669141081,\n",
       "  0.06297069845928085,\n",
       "  0.059239507880475786,\n",
       "  0.055557227600365876,\n",
       "  0.05448735023124351,\n",
       "  0.051739238533708785,\n",
       "  0.050348256093760334,\n",
       "  0.04779590860837036,\n",
       "  0.046431589002410574,\n",
       "  0.04375633341777656,\n",
       "  0.04335437549485101,\n",
       "  0.0413533840328455,\n",
       "  0.04036232121288776,\n",
       "  0.03954756963584158,\n",
       "  0.03782269079238176,\n",
       "  0.037442554854270484,\n",
       "  0.03541679496152533,\n",
       "  0.03422635021722979,\n",
       "  0.03186399551729361,\n",
       "  0.03153090291760034,\n",
       "  0.03102111884703239,\n",
       "  0.029809166428943476,\n",
       "  0.02905234541847474,\n",
       "  0.02728340963108672,\n",
       "  0.027637300205727418,\n",
       "  0.027554908881170882,\n",
       "  0.026532549473146597,\n",
       "  0.025309749713374508,\n",
       "  0.024759572558104993,\n",
       "  0.02479303940716717,\n",
       "  0.024541440797555776,\n",
       "  0.023465162510466243,\n",
       "  0.021704002718130746,\n",
       "  0.02166307804485162,\n",
       "  0.021954151491324108,\n",
       "  0.021642173961218862,\n",
       "  0.020619114752237995,\n",
       "  0.019732913007545802,\n",
       "  0.019734069725705516,\n",
       "  0.02023508144646055,\n",
       "  0.019031532543400922,\n",
       "  0.01824976564902398,\n",
       "  0.018096455838531256,\n",
       "  0.017036394868046045,\n",
       "  0.01764921309529907,\n",
       "  0.01668515598349687,\n",
       "  0.015905161905619834,\n",
       "  0.016144806343234248,\n",
       "  0.016555106846822633,\n",
       "  0.015468389755632314,\n",
       "  0.015167834066475431,\n",
       "  0.01469805262879365,\n",
       "  0.014674714957881306,\n",
       "  0.014026585394620067,\n",
       "  0.013936515975122651,\n",
       "  0.01362536781364017,\n",
       "  0.013487351473627819,\n",
       "  0.012876412818311818,\n",
       "  0.013042219679078294,\n",
       "  0.012712313643553191,\n",
       "  0.012464956204510397,\n",
       "  0.011860070030929313,\n",
       "  0.012189893499534163,\n",
       "  0.011718336409992642,\n",
       "  0.011378153801585238,\n",
       "  0.011656971389634741,\n",
       "  0.011266294815060165,\n",
       "  0.011567544960416853,\n",
       "  0.010754821765133076,\n",
       "  0.010662803873937162,\n",
       "  0.010723148643349608,\n",
       "  0.01038057710458007,\n",
       "  0.010024556794410779,\n",
       "  0.00996523986880978,\n",
       "  0.010144771182806128,\n",
       "  0.00977470215358254,\n",
       "  0.009534295462071896,\n",
       "  0.0094191923401215],\n",
       " [1.2918465435504913,\n",
       "  0.5655098358790079,\n",
       "  0.36555234094460803,\n",
       "  0.27972996421158314,\n",
       "  0.2252084438999494,\n",
       "  0.19589821932216486,\n",
       "  0.18170556363960108,\n",
       "  0.1651856228709221,\n",
       "  0.14842553188403448,\n",
       "  0.14021647038559118,\n",
       "  0.1332269043972095,\n",
       "  0.1413883681719502,\n",
       "  0.13208184329171976,\n",
       "  0.12013100041076541,\n",
       "  0.11647121980786324,\n",
       "  0.11634501907974482,\n",
       "  0.118060030353566,\n",
       "  0.10447654966264963,\n",
       "  0.09974571053559582,\n",
       "  0.10730622134481867,\n",
       "  0.10235512613629301,\n",
       "  0.09619979870816071,\n",
       "  0.1017786458445092,\n",
       "  0.09579201244438688,\n",
       "  0.09436343517154455,\n",
       "  0.09692161491451164,\n",
       "  0.09231884762023886,\n",
       "  0.09285516198724508,\n",
       "  0.09240484959445894,\n",
       "  0.08969123366599281,\n",
       "  0.09135167199807863,\n",
       "  0.08962979540228844,\n",
       "  0.09217172154846291,\n",
       "  0.08865428195955853,\n",
       "  0.09084847002911071,\n",
       "  0.08696615773563583,\n",
       "  0.09913912337894241,\n",
       "  0.0877062954629461,\n",
       "  0.09024397493340075,\n",
       "  0.08896678080782294,\n",
       "  0.0928453862046202,\n",
       "  0.09234435976638149,\n",
       "  0.08869936418098708,\n",
       "  0.08898206482020517,\n",
       "  0.08808236957217257,\n",
       "  0.08948289121811588,\n",
       "  0.08843539267157514,\n",
       "  0.08809833802903692,\n",
       "  0.0870251648593694,\n",
       "  0.0903803971208011,\n",
       "  0.09361115555899839,\n",
       "  0.08937365965296824,\n",
       "  0.09058863716199994,\n",
       "  0.09140166915797938,\n",
       "  0.09390862693544477,\n",
       "  0.08913027673649292,\n",
       "  0.08927973278332502,\n",
       "  0.08919051052847256,\n",
       "  0.08963028395858903,\n",
       "  0.08900793191666405,\n",
       "  0.09094169417706628,\n",
       "  0.08926856541074812,\n",
       "  0.08860800326025735,\n",
       "  0.08919783844612539,\n",
       "  0.0889099429283912,\n",
       "  0.09149915593055387,\n",
       "  0.09239753479293238,\n",
       "  0.09007848465504746,\n",
       "  0.08885344944428653,\n",
       "  0.09018041224529345,\n",
       "  0.09188322136954714,\n",
       "  0.08880613200987379,\n",
       "  0.0909685647347942,\n",
       "  0.08957101800478995,\n",
       "  0.09037877630908042,\n",
       "  0.09346122077355783,\n",
       "  0.09056744759436697,\n",
       "  0.09107063186820596,\n",
       "  0.09022505069151521,\n",
       "  0.09360825996069859,\n",
       "  0.090798417183881,\n",
       "  0.09115648735314608,\n",
       "  0.09310970618389547,\n",
       "  0.09436457340295117,\n",
       "  0.09098407866743703,\n",
       "  0.09305977829111119,\n",
       "  0.09331318592497458,\n",
       "  0.09132242761552334,\n",
       "  0.09255148482043296,\n",
       "  0.09409354574745521,\n",
       "  0.09212345090539505,\n",
       "  0.09390293585602194,\n",
       "  0.09432312081723164,\n",
       "  0.09322711344187458,\n",
       "  0.09439794005205233,\n",
       "  0.0922819960784788,\n",
       "  0.0938133819339176,\n",
       "  0.09392942404762532,\n",
       "  0.0946479463018477,\n",
       "  0.09365276930232842],\n",
       " [0.7604166666666666,\n",
       "  0.890625,\n",
       "  0.890625,\n",
       "  0.9270833333333334,\n",
       "  0.9401041666666666,\n",
       "  0.9375,\n",
       "  0.953125,\n",
       "  0.9453125,\n",
       "  0.9583333333333334,\n",
       "  0.9609375,\n",
       "  0.9583333333333334,\n",
       "  0.9609375,\n",
       "  0.9583333333333334,\n",
       "  0.9609375,\n",
       "  0.9609375,\n",
       "  0.9635416666666666,\n",
       "  0.9661458333333334,\n",
       "  0.9739583333333334,\n",
       "  0.96875,\n",
       "  0.9635416666666666,\n",
       "  0.9765625,\n",
       "  0.96875,\n",
       "  0.9661458333333334,\n",
       "  0.9713541666666666,\n",
       "  0.9713541666666666,\n",
       "  0.9713541666666666,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9713541666666666,\n",
       "  0.9713541666666666,\n",
       "  0.9739583333333334,\n",
       "  0.9765625,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9661458333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9713541666666666,\n",
       "  0.9713541666666666,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9713541666666666,\n",
       "  0.9713541666666666,\n",
       "  0.9739583333333334,\n",
       "  0.9791666666666666,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9713541666666666,\n",
       "  0.9713541666666666,\n",
       "  0.9765625,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9713541666666666,\n",
       "  0.9739583333333334,\n",
       "  0.9713541666666666,\n",
       "  0.9739583333333334,\n",
       "  0.9765625,\n",
       "  0.9739583333333334,\n",
       "  0.9765625,\n",
       "  0.9739583333333334,\n",
       "  0.9765625,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9713541666666666,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9713541666666666,\n",
       "  0.9739583333333334,\n",
       "  0.9713541666666666,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334,\n",
       "  0.9713541666666666,\n",
       "  0.9713541666666666,\n",
       "  0.9739583333333334,\n",
       "  0.9713541666666666,\n",
       "  0.9739583333333334,\n",
       "  0.9713541666666666,\n",
       "  0.9739583333333334,\n",
       "  0.9739583333333334])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refactoring後の学習ループ\n",
    "# early_stopping=None にすると、early stoppingせず100回学習ループを回す\n",
    "num_in = 64\n",
    "num_hidden = 30\n",
    "num_out = 10\n",
    "model = MLP(num_in, num_hidden, num_out)\n",
    "learning_rate = 0.1\n",
    "opt = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epoch = 100\n",
    "learn(model, train_loader, val_loader, opt, loss_func=F.cross_entropy, num_epoch=num_epoch, early_stopping=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a71ac-9dea-460d-b499-6626275cc49f",
   "metadata": {},
   "source": [
    "## モデルオブジェクトの保存とロード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef554c-6384-4504-bd52-bf9d44866eb9",
   "metadata": {},
   "source": [
    "- torch.save(): モデルを指定したパスに保存する\n",
    "    - obj引数: 指定するモデルオブジェクト\n",
    "    - ｆ引数: 保存するモデルのファイル名やパス\n",
    "- torch.load(): したいしたパスからモデルをロードする\n",
    "    - f引数: ロードするモデルのファイル名やパス\n",
    "- 拡張子に'.pth'を使う習慣がある\n",
    "- 保存後にコードを変更した場合や、異なる環境でロードした際に予期しない問題が起こる可能性があることに注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f97075f9-aa7a-42d7-a520-577651e99abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (l1): Linear(in_features=64, out_features=30, bias=True)\n",
       "  (l2): Linear(in_features=30, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下記のモデルを保存する\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f0c0c17-9742-4823-8fb5-c29ba909aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "torch.save(model, 'sample_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0289e65-3b62-4307-bf91-ac22871e76c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (l1): Linear(in_features=64, out_features=30, bias=True)\n",
       "  (l2): Linear(in_features=30, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルのロード\n",
    "loaded_model = torch.load('sample_model.pth')\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec995b1-47cf-4bb3-a1b0-d5d113880721",
   "metadata": {},
   "source": [
    "## モデルのパラメータの保存とロード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5493d14-8e7c-42dc-bfa8-7e57e51a3f2f",
   "metadata": {},
   "source": [
    "- 一般的に、オブジェクトの保存/ロードよりも推奨される\n",
    "- .state_dict()でモデルのパラメータの情報のみを取り出す\n",
    "- パラメータのみ切り出して保存することで、パラメータに関連するコード以外が変更されてもロードし使用することができる\n",
    "- Optimizerについて同様にパラメータを保存することができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a762065e-5303-444b-beab-64de1062a78b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('l1.weight',\n",
       "              tensor([[-0.1965, -0.0512,  0.2085,  ..., -0.4177, -0.3376, -0.2459],\n",
       "                      [ 0.0272, -0.0209, -0.0410,  ...,  0.1517, -0.0434,  0.1746],\n",
       "                      [ 0.0386, -0.1325, -0.2171,  ...,  0.0231,  0.0510, -0.0562],\n",
       "                      ...,\n",
       "                      [-0.0632, -0.0214, -0.1154,  ...,  0.4278,  0.1264,  0.0017],\n",
       "                      [-0.0072, -0.1656,  0.0464,  ..., -0.2474, -0.3255, -0.0025],\n",
       "                      [-0.0829, -0.0964, -0.2186,  ...,  0.0592, -0.0247,  0.0830]])),\n",
       "             ('l1.bias',\n",
       "              tensor([-0.0516,  0.1185,  0.1303,  0.1745, -0.0989,  0.0873, -0.0234,  0.0137,\n",
       "                      -0.0151, -0.0329,  0.0424,  0.0775,  0.1056,  0.0138, -0.0693, -0.0518,\n",
       "                       0.0917, -0.0286,  0.0364, -0.0893,  0.0873, -0.0806, -0.0507,  0.1187,\n",
       "                       0.0695,  0.0540,  0.2147, -0.0672,  0.0184,  0.1336])),\n",
       "             ('l2.weight',\n",
       "              tensor([[ 8.6357e-01, -1.9148e-01, -7.0937e-01,  4.4161e-01,  4.8167e-02,\n",
       "                       -2.5190e-02, -2.1823e-01,  2.0353e-01, -1.1465e-01, -1.4444e-01,\n",
       "                       -1.7539e-01, -3.0720e-01,  1.2991e-01,  9.6022e-02, -4.0108e-01,\n",
       "                       -8.4365e-01,  2.8734e-02,  9.3670e-02,  7.8700e-01, -5.6158e-01,\n",
       "                       -1.5400e-02,  3.4491e-01, -5.9454e-02,  2.8478e-01, -2.0027e-01,\n",
       "                       -4.9189e-01, -4.3217e-01, -2.4755e-01,  6.3322e-01,  6.9646e-04],\n",
       "                      [-5.7863e-01,  6.8188e-01, -1.4423e-01, -2.9865e-01,  1.5101e-01,\n",
       "                       -1.8569e-01, -5.1341e-01, -3.4882e-01, -7.0648e-02, -1.1502e-01,\n",
       "                        9.7551e-02, -7.0893e-01, -2.7495e-01,  4.0264e-01,  5.1347e-01,\n",
       "                       -2.1426e-01,  4.6980e-01, -7.7277e-01, -9.6822e-01,  6.5500e-01,\n",
       "                       -1.1044e-01,  3.6281e-01,  3.7073e-01, -3.0705e-01,  1.5002e-01,\n",
       "                        4.1863e-01,  1.8029e-01,  6.2686e-01, -8.7098e-02,  5.6772e-01],\n",
       "                      [-5.2462e-01, -2.1074e-01, -2.7675e-01,  2.9582e-01, -1.5351e-01,\n",
       "                        5.9837e-02,  1.7310e-01,  3.5255e-01,  5.4757e-02, -1.2128e-01,\n",
       "                       -7.9637e-02,  2.0630e-01, -7.0110e-02,  1.2326e+00,  4.3484e-01,\n",
       "                        1.8807e-01,  2.5004e-01,  5.5877e-01, -3.8431e-01,  8.4060e-01,\n",
       "                       -8.4645e-02,  1.0495e-01,  2.0726e-01, -1.8615e-01, -6.1881e-01,\n",
       "                        1.8831e-01, -1.2967e+00, -1.0131e-01, -6.5411e-01, -3.9463e-01],\n",
       "                      [-2.5158e-01, -3.8985e-01,  3.7783e-01, -3.5233e-02, -3.1744e-01,\n",
       "                       -2.9114e-02, -8.9627e-02,  4.5651e-01,  1.7204e-01, -9.8492e-02,\n",
       "                       -1.5629e-01,  3.2775e-01,  3.3263e-02, -5.6189e-01, -5.0077e-01,\n",
       "                        1.4099e+00, -2.6401e-01,  5.3681e-03,  5.0413e-01,  2.9731e-02,\n",
       "                       -8.8181e-02, -2.9815e-01, -2.3845e-01, -6.0817e-01, -1.1658e-01,\n",
       "                        8.8587e-02, -4.6344e-01,  6.2365e-01,  3.6229e-02, -8.5930e-01],\n",
       "                      [ 2.6538e-01, -3.3583e-01, -4.7508e-01, -7.5509e-02,  1.6054e-02,\n",
       "                       -6.6388e-02,  1.5196e-02, -4.5338e-01, -2.7420e-02,  1.1439e-01,\n",
       "                        6.0571e-02, -6.0436e-01,  3.3921e-01,  2.4388e-03, -1.2166e-01,\n",
       "                       -6.5318e-01,  2.2977e-01, -1.0875e-01,  3.8368e-02, -3.8354e-01,\n",
       "                       -1.5670e-01, -2.1267e-01, -1.7866e-01,  2.0663e-01, -7.2099e-02,\n",
       "                        6.3700e-01,  1.5081e+00, -1.3491e-01, -7.4305e-01,  2.2122e-01],\n",
       "                      [ 9.2746e-01,  2.8131e-01, -2.2400e-01,  2.2197e-01, -5.7957e-01,\n",
       "                       -1.5249e-01, -2.0700e-02, -1.2556e-01,  4.7627e-02, -3.9016e-02,\n",
       "                       -3.6575e-03,  6.1607e-01, -4.4993e-02, -6.3278e-01,  9.4425e-01,\n",
       "                        2.7167e-01, -8.2466e-02, -7.8321e-01, -3.7630e-01, -4.3961e-03,\n",
       "                        1.3535e-01,  3.0737e-01, -1.0211e+00, -1.7778e-01,  1.1291e-01,\n",
       "                       -2.4791e-01, -1.6075e-01, -2.8447e-01,  4.8493e-01,  4.4834e-02],\n",
       "                      [-1.0063e-01,  4.9240e-01, -1.7300e-01, -2.3153e-01,  2.5538e-01,\n",
       "                       -7.1056e-02,  2.6379e-01,  9.0129e-02, -9.7404e-02, -8.1568e-02,\n",
       "                        9.7003e-02,  3.9145e-01,  2.9355e-01,  3.6589e-01,  4.9602e-01,\n",
       "                       -7.0524e-01,  1.0405e-01, -5.0878e-01,  9.2600e-01, -1.3365e-01,\n",
       "                        1.6935e-01, -1.7683e-01,  5.7133e-01, -5.1860e-01,  1.0002e-01,\n",
       "                       -4.9463e-01, -9.3859e-03,  1.7827e-01, -6.4687e-01, -5.9753e-02],\n",
       "                      [-3.1654e-01, -1.6657e-01,  3.0050e-01,  9.0350e-02,  1.2613e-02,\n",
       "                        5.0378e-02,  5.1565e-02,  7.8383e-04, -3.5908e-03,  1.0997e-01,\n",
       "                        6.8274e-02,  1.4398e-01, -2.3379e-01,  5.3466e-01, -6.4351e-01,\n",
       "                       -1.8992e-01, -9.9313e-02,  3.6490e-01, -2.6840e-01, -7.3890e-01,\n",
       "                        1.5102e-01, -1.5631e-01, -8.8340e-01,  7.9291e-01,  7.2669e-01,\n",
       "                        8.0303e-01,  1.7428e-01, -3.4598e-01, -1.6265e-01, -3.3663e-01],\n",
       "                      [-3.6959e-01,  3.7726e-01, -6.5913e-01, -3.2560e-01,  7.7989e-01,\n",
       "                       -4.2851e-02,  4.1255e-01, -9.5272e-02,  1.2262e-01,  1.6961e-01,\n",
       "                        8.7583e-02, -2.0802e-02, -6.9703e-01, -4.4821e-01, -2.1522e-01,\n",
       "                        5.4245e-01,  1.1514e-01,  2.9718e-01,  1.4336e-01,  1.4119e-02,\n",
       "                        1.1849e-03,  1.2473e-02,  9.0875e-01, -1.0962e-02,  8.4457e-02,\n",
       "                       -5.8391e-01,  2.1955e-01, -5.4383e-01,  3.2366e-01, -1.0381e-01],\n",
       "                      [ 2.9694e-01, -2.7430e-01,  7.1317e-01, -4.7062e-01, -3.7602e-01,\n",
       "                       -8.1658e-02,  2.9251e-03,  1.0329e-01,  7.7510e-03,  7.9180e-03,\n",
       "                        3.8008e-02, -9.9155e-02, -2.7592e-01, -1.2212e+00, -8.4013e-01,\n",
       "                       -1.1250e-02, -3.4381e-01,  2.3823e-01, -2.6374e-01,  6.3634e-01,\n",
       "                        1.5391e-01,  3.7761e-02,  2.3620e-01,  4.8137e-01, -1.0758e-01,\n",
       "                       -4.4494e-01, -1.9184e-01, -2.9324e-01,  7.3550e-01,  7.5156e-01]])),\n",
       "             ('l2.bias',\n",
       "              tensor([ 0.1306, -0.0706, -0.0814, -0.0042,  0.1109, -0.0406, -0.1009, -0.1665,\n",
       "                      -0.1898,  0.2498]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = model.state_dict()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "528526d9-3e24-4baa-8669-41fbba5bfb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 別のモデルを作成しparamsを呼び出す\n",
    "another_model = MLP(64, 30, 10)\n",
    "another_model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ff27f5d-79cf-4bcb-ba9d-ee9c7d0756df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1965, -0.0512,  0.2085,  ..., -0.4177, -0.3376, -0.2459],\n",
       "         [ 0.0272, -0.0209, -0.0410,  ...,  0.1517, -0.0434,  0.1746],\n",
       "         [ 0.0386, -0.1325, -0.2171,  ...,  0.0231,  0.0510, -0.0562],\n",
       "         ...,\n",
       "         [-0.0632, -0.0214, -0.1154,  ...,  0.4278,  0.1264,  0.0017],\n",
       "         [-0.0072, -0.1656,  0.0464,  ..., -0.2474, -0.3255, -0.0025],\n",
       "         [-0.0829, -0.0964, -0.2186,  ...,  0.0592, -0.0247,  0.0830]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0516,  0.1185,  0.1303,  0.1745, -0.0989,  0.0873, -0.0234,  0.0137,\n",
       "         -0.0151, -0.0329,  0.0424,  0.0775,  0.1056,  0.0138, -0.0693, -0.0518,\n",
       "          0.0917, -0.0286,  0.0364, -0.0893,  0.0873, -0.0806, -0.0507,  0.1187,\n",
       "          0.0695,  0.0540,  0.2147, -0.0672,  0.0184,  0.1336],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 8.6357e-01, -1.9148e-01, -7.0937e-01,  4.4161e-01,  4.8167e-02,\n",
       "          -2.5190e-02, -2.1823e-01,  2.0353e-01, -1.1465e-01, -1.4444e-01,\n",
       "          -1.7539e-01, -3.0720e-01,  1.2991e-01,  9.6022e-02, -4.0108e-01,\n",
       "          -8.4365e-01,  2.8734e-02,  9.3670e-02,  7.8700e-01, -5.6158e-01,\n",
       "          -1.5400e-02,  3.4491e-01, -5.9454e-02,  2.8478e-01, -2.0027e-01,\n",
       "          -4.9189e-01, -4.3217e-01, -2.4755e-01,  6.3322e-01,  6.9646e-04],\n",
       "         [-5.7863e-01,  6.8188e-01, -1.4423e-01, -2.9865e-01,  1.5101e-01,\n",
       "          -1.8569e-01, -5.1341e-01, -3.4882e-01, -7.0648e-02, -1.1502e-01,\n",
       "           9.7551e-02, -7.0893e-01, -2.7495e-01,  4.0264e-01,  5.1347e-01,\n",
       "          -2.1426e-01,  4.6980e-01, -7.7277e-01, -9.6822e-01,  6.5500e-01,\n",
       "          -1.1044e-01,  3.6281e-01,  3.7073e-01, -3.0705e-01,  1.5002e-01,\n",
       "           4.1863e-01,  1.8029e-01,  6.2686e-01, -8.7098e-02,  5.6772e-01],\n",
       "         [-5.2462e-01, -2.1074e-01, -2.7675e-01,  2.9582e-01, -1.5351e-01,\n",
       "           5.9837e-02,  1.7310e-01,  3.5255e-01,  5.4757e-02, -1.2128e-01,\n",
       "          -7.9637e-02,  2.0630e-01, -7.0110e-02,  1.2326e+00,  4.3484e-01,\n",
       "           1.8807e-01,  2.5004e-01,  5.5877e-01, -3.8431e-01,  8.4060e-01,\n",
       "          -8.4645e-02,  1.0495e-01,  2.0726e-01, -1.8615e-01, -6.1881e-01,\n",
       "           1.8831e-01, -1.2967e+00, -1.0131e-01, -6.5411e-01, -3.9463e-01],\n",
       "         [-2.5158e-01, -3.8985e-01,  3.7783e-01, -3.5233e-02, -3.1744e-01,\n",
       "          -2.9114e-02, -8.9627e-02,  4.5651e-01,  1.7204e-01, -9.8492e-02,\n",
       "          -1.5629e-01,  3.2775e-01,  3.3263e-02, -5.6189e-01, -5.0077e-01,\n",
       "           1.4099e+00, -2.6401e-01,  5.3681e-03,  5.0413e-01,  2.9731e-02,\n",
       "          -8.8181e-02, -2.9815e-01, -2.3845e-01, -6.0817e-01, -1.1658e-01,\n",
       "           8.8587e-02, -4.6344e-01,  6.2365e-01,  3.6229e-02, -8.5930e-01],\n",
       "         [ 2.6538e-01, -3.3583e-01, -4.7508e-01, -7.5509e-02,  1.6054e-02,\n",
       "          -6.6388e-02,  1.5196e-02, -4.5338e-01, -2.7420e-02,  1.1439e-01,\n",
       "           6.0571e-02, -6.0436e-01,  3.3921e-01,  2.4388e-03, -1.2166e-01,\n",
       "          -6.5318e-01,  2.2977e-01, -1.0875e-01,  3.8368e-02, -3.8354e-01,\n",
       "          -1.5670e-01, -2.1267e-01, -1.7866e-01,  2.0663e-01, -7.2099e-02,\n",
       "           6.3700e-01,  1.5081e+00, -1.3491e-01, -7.4305e-01,  2.2122e-01],\n",
       "         [ 9.2746e-01,  2.8131e-01, -2.2400e-01,  2.2197e-01, -5.7957e-01,\n",
       "          -1.5249e-01, -2.0700e-02, -1.2556e-01,  4.7627e-02, -3.9016e-02,\n",
       "          -3.6575e-03,  6.1607e-01, -4.4993e-02, -6.3278e-01,  9.4425e-01,\n",
       "           2.7167e-01, -8.2466e-02, -7.8321e-01, -3.7630e-01, -4.3961e-03,\n",
       "           1.3535e-01,  3.0737e-01, -1.0211e+00, -1.7778e-01,  1.1291e-01,\n",
       "          -2.4791e-01, -1.6075e-01, -2.8447e-01,  4.8493e-01,  4.4834e-02],\n",
       "         [-1.0063e-01,  4.9240e-01, -1.7300e-01, -2.3153e-01,  2.5538e-01,\n",
       "          -7.1056e-02,  2.6379e-01,  9.0129e-02, -9.7404e-02, -8.1568e-02,\n",
       "           9.7003e-02,  3.9145e-01,  2.9355e-01,  3.6589e-01,  4.9602e-01,\n",
       "          -7.0524e-01,  1.0405e-01, -5.0878e-01,  9.2600e-01, -1.3365e-01,\n",
       "           1.6935e-01, -1.7683e-01,  5.7133e-01, -5.1860e-01,  1.0002e-01,\n",
       "          -4.9463e-01, -9.3859e-03,  1.7827e-01, -6.4687e-01, -5.9753e-02],\n",
       "         [-3.1654e-01, -1.6657e-01,  3.0050e-01,  9.0350e-02,  1.2613e-02,\n",
       "           5.0378e-02,  5.1565e-02,  7.8383e-04, -3.5908e-03,  1.0997e-01,\n",
       "           6.8274e-02,  1.4398e-01, -2.3379e-01,  5.3466e-01, -6.4351e-01,\n",
       "          -1.8992e-01, -9.9313e-02,  3.6490e-01, -2.6840e-01, -7.3890e-01,\n",
       "           1.5102e-01, -1.5631e-01, -8.8340e-01,  7.9291e-01,  7.2669e-01,\n",
       "           8.0303e-01,  1.7428e-01, -3.4598e-01, -1.6265e-01, -3.3663e-01],\n",
       "         [-3.6959e-01,  3.7726e-01, -6.5913e-01, -3.2560e-01,  7.7989e-01,\n",
       "          -4.2851e-02,  4.1255e-01, -9.5272e-02,  1.2262e-01,  1.6961e-01,\n",
       "           8.7583e-02, -2.0802e-02, -6.9703e-01, -4.4821e-01, -2.1522e-01,\n",
       "           5.4245e-01,  1.1514e-01,  2.9718e-01,  1.4336e-01,  1.4119e-02,\n",
       "           1.1849e-03,  1.2473e-02,  9.0875e-01, -1.0962e-02,  8.4457e-02,\n",
       "          -5.8391e-01,  2.1955e-01, -5.4383e-01,  3.2366e-01, -1.0381e-01],\n",
       "         [ 2.9694e-01, -2.7430e-01,  7.1317e-01, -4.7062e-01, -3.7602e-01,\n",
       "          -8.1658e-02,  2.9251e-03,  1.0329e-01,  7.7510e-03,  7.9180e-03,\n",
       "           3.8008e-02, -9.9155e-02, -2.7592e-01, -1.2212e+00, -8.4013e-01,\n",
       "          -1.1250e-02, -3.4381e-01,  2.3823e-01, -2.6374e-01,  6.3634e-01,\n",
       "           1.5391e-01,  3.7761e-02,  2.3620e-01,  4.8137e-01, -1.0758e-01,\n",
       "          -4.4494e-01, -1.9184e-01, -2.9324e-01,  7.3550e-01,  7.5156e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1306, -0.0706, -0.0814, -0.0042,  0.1109, -0.0406, -0.1009, -0.1665,\n",
       "         -0.1898,  0.2498], requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(another_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a249daf-f4b8-437b-b863-7c5e8ab7a1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1965, -0.0512,  0.2085,  ..., -0.4177, -0.3376, -0.2459],\n",
       "        [ 0.0272, -0.0209, -0.0410,  ...,  0.1517, -0.0434,  0.1746],\n",
       "        [ 0.0386, -0.1325, -0.2171,  ...,  0.0231,  0.0510, -0.0562],\n",
       "        ...,\n",
       "        [-0.0632, -0.0214, -0.1154,  ...,  0.4278,  0.1264,  0.0017],\n",
       "        [-0.0072, -0.1656,  0.0464,  ..., -0.2474, -0.3255, -0.0025],\n",
       "        [-0.0829, -0.0964, -0.2186,  ...,  0.0592, -0.0247,  0.0830]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modelとanother_modelの比較\n",
    "another_model.l1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2783d60-00ae-4e1f-9194-bc33187e7bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1965, -0.0512,  0.2085,  ..., -0.4177, -0.3376, -0.2459],\n",
       "        [ 0.0272, -0.0209, -0.0410,  ...,  0.1517, -0.0434,  0.1746],\n",
       "        [ 0.0386, -0.1325, -0.2171,  ...,  0.0231,  0.0510, -0.0562],\n",
       "        ...,\n",
       "        [-0.0632, -0.0214, -0.1154,  ...,  0.4278,  0.1264,  0.0017],\n",
       "        [-0.0072, -0.1656,  0.0464,  ..., -0.2474, -0.3255, -0.0025],\n",
       "        [-0.0829, -0.0964, -0.2186,  ...,  0.0592, -0.0247,  0.0830]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63bbd74e-4dd6-49e4-8ec6-4d15e846a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのパラメータの保存\n",
    "torch.save(model.state_dict(), 'sample_model_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a5475ee-adee-4119-9cb1-d64d5e2e0176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルのパラメータのロード\n",
    "another_model.load_state_dict(torch.load('sample_model_dict.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de15cf9e-42a9-45f7-9fa0-7e70615eb805",
   "metadata": {},
   "source": [
    "## 学習ループ中にモデルを保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d503911b-2138-4419-929b-3a7d63942a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============自作学習ループ関数=============\n",
    "def learn(model, train_loader, val_loader, opt, loss_func, num_epoch, early_stopping=None, save_path=None):\n",
    "    # ログ\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_loss = float('inf')  # 1回目のval_lossを無限大とする\n",
    "    no_improve = 0 # early stoppingのカウント用変数\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        running_loss = 0.0\n",
    "        running_val_loss = 0.0\n",
    "        running_val_accuracy = 0.0\n",
    "        \n",
    "        for train_batch, data in enumerate(train_loader):\n",
    "            \n",
    "            X, y = data\n",
    "            \n",
    "            # mini batch作成 -> 削除\n",
    "    \n",
    "            # 順伝播と逆伝播の計算\n",
    "            opt.zero_grad()\n",
    "            # forward\n",
    "            preds = model.forward(X) \n",
    "            loss = loss_func(preds, y)\n",
    "            running_loss += loss.item()\n",
    "            # backward\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            for val_batch, data in enumerate(val_loader):\n",
    "                X_val, y_val = data\n",
    "                \n",
    "                preds_val = model(X_val)  \n",
    "                val_loss = loss_func(preds_val, y_val)\n",
    "                running_val_loss += val_loss.item()\n",
    "                val_accuracy = torch.sum(torch.argmax(preds_val, dim=-1) == y_val) / y_val.shape[0] \n",
    "                running_val_accuracy += val_accuracy.item()\n",
    "    \n",
    "        train_losses.append(running_loss/(train_batch + 1))\n",
    "        val_losses.append(running_val_loss/(val_batch + 1))\n",
    "        val_accuracies.append(running_val_accuracy/(val_batch + 1))\n",
    "        print(f'epoch: {epoch}: train error: {train_losses[-1]}, validation error: {val_losses[-1]}, validation accuracy: {val_accuracies[-1]}')\n",
    "    \n",
    "        # early ｓｔｏｐｐｉｎｇ\n",
    "        if val_losses[-1] < best_val_loss:\n",
    "            best_val_loss = val_losses[-1]\n",
    "            no_improve = 0\n",
    "            # モデルの保存\n",
    "            if save_path is not None:\n",
    "                state = {\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': opt.state_dict(),\n",
    "                    'val_loss': val_losses[-1]\n",
    "                }\n",
    "                torch.save(state, save_path)\n",
    "        else:\n",
    "            no_improve += 1\n",
    "    \n",
    "        if early_stopping and no_improve >= early_stopping:\n",
    "            print('Stoping early')\n",
    "            break\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1dd506ca-dae7-4fce-9983-a64f5193d229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0: train error: 1.9023839049869113, validation error: 1.342312604188919, validation accuracy: 0.84375\n",
      "epoch: 1: train error: 0.9147914926211039, validation error: 0.5974241395791372, validation accuracy: 0.8802083333333334\n",
      "epoch: 2: train error: 0.46239323251777226, validation error: 0.3844735150535901, validation accuracy: 0.9114583333333334\n",
      "epoch: 3: train error: 0.3152361283699671, validation error: 0.2801151362558206, validation accuracy: 0.9401041666666666\n",
      "epoch: 4: train error: 0.24528408249219258, validation error: 0.23144044975439707, validation accuracy: 0.9296875\n",
      "epoch: 5: train error: 0.2006888962454266, validation error: 0.21848738193511963, validation accuracy: 0.9375\n",
      "epoch: 6: train error: 0.1760530422959063, validation error: 0.19482566912968954, validation accuracy: 0.9479166666666666\n",
      "epoch: 7: train error: 0.1555503295527564, validation error: 0.1763042143235604, validation accuracy: 0.9505208333333334\n",
      "epoch: 8: train error: 0.14372090167469448, validation error: 0.15513638593256474, validation accuracy: 0.9479166666666666\n",
      "epoch: 9: train error: 0.13259217118223507, validation error: 0.146747766683499, validation accuracy: 0.9479166666666666\n",
      "epoch: 10: train error: 0.12282358987463846, validation error: 0.14609996881335974, validation accuracy: 0.9583333333333334\n",
      "epoch: 11: train error: 0.1147909322546588, validation error: 0.13239838959028324, validation accuracy: 0.9609375\n",
      "epoch: 12: train error: 0.10809568907651636, validation error: 0.12565928449233374, validation accuracy: 0.9583333333333334\n",
      "epoch: 13: train error: 0.09804999083280563, validation error: 0.12891249731183052, validation accuracy: 0.9583333333333334\n",
      "epoch: 14: train error: 0.09520742812504371, validation error: 0.1258414232482513, validation accuracy: 0.9713541666666666\n",
      "epoch: 15: train error: 0.09272469814038939, validation error: 0.11452683884029587, validation accuracy: 0.9635416666666666\n",
      "epoch: 16: train error: 0.08562432813147704, validation error: 0.11904159374535084, validation accuracy: 0.9713541666666666\n",
      "epoch: 17: train error: 0.08187795840203763, validation error: 0.11405583129574855, validation accuracy: 0.9739583333333334\n",
      "epoch: 18: train error: 0.07723157743199004, validation error: 0.11092143350591262, validation accuracy: 0.9661458333333334\n",
      "epoch: 19: train error: 0.07521478581345743, validation error: 0.1091227646296223, validation accuracy: 0.9661458333333334\n",
      "epoch: 20: train error: 0.07164977466066678, validation error: 0.10770362646629413, validation accuracy: 0.9739583333333334\n",
      "epoch: 21: train error: 0.06695606066948838, validation error: 0.12139992912610371, validation accuracy: 0.9583333333333334\n",
      "epoch: 22: train error: 0.06428433350390858, validation error: 0.10679773846641183, validation accuracy: 0.96875\n",
      "epoch: 23: train error: 0.06357742204434341, validation error: 0.11301737061391275, validation accuracy: 0.9635416666666666\n",
      "epoch: 24: train error: 0.06344236069255405, validation error: 0.10250084567815065, validation accuracy: 0.9739583333333334\n",
      "epoch: 25: train error: 0.05738286255962319, validation error: 0.10159541790684064, validation accuracy: 0.9739583333333334\n",
      "epoch: 26: train error: 0.05901025103198158, validation error: 0.10264198357860248, validation accuracy: 0.9713541666666666\n",
      "epoch: 27: train error: 0.05416960544470284, validation error: 0.09961956863602002, validation accuracy: 0.9739583333333334\n",
      "epoch: 28: train error: 0.051355781737301084, validation error: 0.09720898761103551, validation accuracy: 0.96875\n",
      "epoch: 29: train error: 0.050815432456632455, validation error: 0.10577821203817923, validation accuracy: 0.9635416666666666\n",
      "epoch: 30: train error: 0.04815303488738007, validation error: 0.10268398079400261, validation accuracy: 0.96875\n",
      "epoch: 31: train error: 0.0461119473601381, validation error: 0.10156346818742652, validation accuracy: 0.9661458333333334\n",
      "epoch: 32: train error: 0.04653736457435621, validation error: 0.09734924067743123, validation accuracy: 0.9739583333333334\n",
      "epoch: 33: train error: 0.04360080991561214, validation error: 0.09922465061148007, validation accuracy: 0.9713541666666666\n",
      "Stoping early\n"
     ]
    }
   ],
   "source": [
    "model = MLP(64, 30, 10)\n",
    "opt = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "train_losses, val_losses, val_accuracies = learn(model, train_loader, val_loader, opt, F.cross_entropy, num_epoch, early_stopping=5, save_path='checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c87fd7f9-87c3-4df6-af2f-884de81227cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルのロード\n",
    "state = torch.load('checkpoint')\n",
    "model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04f20b6d-a95d-4c6a-b8d2-35859d8d4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizerのロード\n",
    "opt.load_state_dict(state['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb2220-0a02-482b-86d1-6557679cec45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
